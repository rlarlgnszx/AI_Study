{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 시퀀스 분류\n"
      ],
      "metadata": {
        "id": "pweqmR-jypfS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSjPeWt1yOjB",
        "outputId": "76d4189b-79d2-4b81-a60c-0fd7d8e44830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SentencePiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68EMkv5yyfiC",
        "outputId": "223edce1-2b96-45d4-8573-a3a8b4153ce7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification,pipeline"
      ],
      "metadata": {
        "id": "g8nCDkWgyUsd"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Negative', 'Positive','Happy','Noraml']\n",
        "id2label={x:y for x,y in zip(range(len(labels)),labels)}"
      ],
      "metadata": {
        "id": "_d5HwL8B2FWu"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load XLNet tokenizer and model\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "## 분류 작업에 따라 num label 레이블 수 변경가능\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=4,id2label=id2label)  # Change num_labels according to your classification task"
      ],
      "metadata": {
        "id": "ySFg6kTTyW_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05772e96-76b2-41df-b302-04f38fb0dbc4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline"
      ],
      "metadata": {
        "id": "Xk2lKrpU6K3k"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generator = pipeline(model='xlnet-base-cased')"
      ],
      "metadata": {
        "id": "vPJfNtLU5USO"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text for classification\n",
        "text = \"The dog is really cute.\""
      ],
      "metadata": {
        "id": "PTwfyPpj7aEy"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generator(text)"
      ],
      "metadata": {
        "id": "fTqaBEII5_6W"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input text\n",
        "inputs = tokenizer.encode_plus(\n",
        "    text,\n",
        "    add_special_tokens=True,\n",
        "    padding='max_length',\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")"
      ],
      "metadata": {
        "id": "SjtjhOJ0yY8B"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOpSo__e5rqI"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "id": "ERRRd8b2z5rB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42d507e-634e-41dd-f3d6-58420aa87934"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "             5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
              "            32,  2288,    27,   343, 10920,     9,     4,     3]]), 'token_type_ids': tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "         0, 0, 0, 0, 0, 0, 0, 2]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform classification\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "predicted_class = torch.argmax(logits, dim=1).item()"
      ],
      "metadata": {
        "id": "l8tgqTHByaId"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## logits가 최종 예측의 클래스를 나타냄"
      ],
      "metadata": {
        "id": "joBrgkno1DRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcPUxQeS1A1K",
        "outputId": "b099d264-5526-4ae7-b3d1-70dc11718f9f"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2138, -0.6524,  0.0614,  0.9373]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXfyq6Njz_cj",
        "outputId": "bb8b8838-5684-4f71-e3e8-a8050d424a83"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 어느정도 제로샷 시퀀스로 분류할수도 있다.\n",
        "## 전달되는 num label이 있기때문에"
      ],
      "metadata": {
        "id": "-o5dNoOE114F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted label\n",
        "labels = ['Negative', 'Positive','Happy','Noraml']  # Replace with your actual class labels\n",
        "## labels 바꾸기 가능\n",
        "predicted_label = labels[predicted_class]\n",
        "\n",
        "print(\"Text:\", text)\n",
        "print(\"Predicted Label:\", predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua58u5xByS5z",
        "outputId": "b8deebbe-8260-4057-97de-0d7761f320e8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: The dog is really cute.\n",
            "Predicted Label: Noraml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXG6li1iy01a"
      },
      "execution_count": 99,
      "outputs": []
    }
  ]
}