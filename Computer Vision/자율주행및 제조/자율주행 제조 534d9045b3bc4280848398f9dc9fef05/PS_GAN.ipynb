{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dikN_Prtnh7a"
      },
      "source": [
        "#Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY9Nx0mbM_OY",
        "outputId": "1c2a54eb-a678-4723-dcd8-b6a6a661bb66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mG0jR_2iEW_",
        "outputId": "b09cdb55-bb00-445c-84ae-179f5eb46b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Pedestrian-Synthesis-GAN'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cd /content/drive/MyDrive/Pedestrian-Synthesis-GAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/computer_vision/02.\\ 자율주행\\ 제조"
      ],
      "metadata": {
        "id": "QocpsQ3EZTqP",
        "outputId": "62d2720c-f052-4b3a-c763-c99378d5f0c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/computer_vision/02. 자율주행 제조'\n",
            "/content/drive/.shortcut-targets-by-id/1OKd3huGNt0Jiva78faTc6dvZGcIZyxx_/[수강생공유용]33개 프로젝트_강의자료 코드/02. 자율주행 제조/코드   데이터/03. pedGan/pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '코드   데이터'"
      ],
      "metadata": {
        "id": "zKXq1wBHZrc_",
        "outputId": "a5313336-ce12-45ca-8380-5805a6c1cf5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1OKd3huGNt0Jiva78faTc6dvZGcIZyxx_/[수강생공유용]33개 프로젝트_강의자료 코드/02. 자율주행 제조/코드   데이터\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd 03.\\ pedGan"
      ],
      "metadata": {
        "id": "h0mcgc-rZ0GB",
        "outputId": "7a522ff7-eb75-48c9-c899-d5033c4082fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1OKd3huGNt0Jiva78faTc6dvZGcIZyxx_/[수강생공유용]33개 프로젝트_강의자료 코드/02. 자율주행 제조/코드   데이터/03. pedGan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd pytorch"
      ],
      "metadata": {
        "id": "CWhVD1ZJZ4Qj",
        "outputId": "393a0608-3eb8-4bb6-8efb-e8a0d1d50eab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1OKd3huGNt0Jiva78faTc6dvZGcIZyxx_/[수강생공유용]33개 프로젝트_강의자료 코드/02. 자율주행 제조/코드   데이터/03. pedGan/pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp -rf Pedestrian-Synthesis-GAN /content/gan"
      ],
      "metadata": {
        "id": "1XZqAQEKZ67E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gan"
      ],
      "metadata": {
        "id": "GZlO2NeyaTR9",
        "outputId": "d60ec80f-e85a-4941-c7c7-a5d1d11c10e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV3YTC0VnamR"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFn1XQC0YFJL",
        "outputId": "a28c5d10-9b75-4b52-80e0-1fc00838e257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting visdom\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from visdom) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom) (2.31.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom) (6.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom) (1.16.0)\n",
            "Collecting jsonpatch (from visdom)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom) (1.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from visdom) (3.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom) (9.4.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->visdom)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom) (2023.7.22)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=c3ada1de128dd706ab4f50127e04f0edae1cf64d0ce1039cf045965a281eeb7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
            "Successfully built visdom\n",
            "Installing collected packages: jsonpointer, jsonpatch, visdom\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 visdom-0.2.4\n",
            "Collecting dominate\n",
            "  Downloading dominate-2.8.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.8.0\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install visdom\n",
        "!pip install dominate\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bZVvPWmn1xD"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vDVQRG_doFDK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "from util import util\n",
        "import torch\n",
        "import numpy as np\n",
        "import ntpath\n",
        "import time\n",
        "from util import html\n",
        "import os.path\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "# from data.base_dataset import BaseDataset\n",
        "from data.image_folder import make_dataset\n",
        "import json\n",
        "import torch.utils.data\n",
        "from data.base_data_loader import BaseDataLoader  #REMEMBER TO REMOVE OPT\n",
        "\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Variable\n",
        "import util.util as util\n",
        "from util.image_pool import ImagePool\n",
        "\n",
        "from copy import deepcopy\n",
        "from models import networks\n",
        "\n",
        "\n",
        "from pdb import set_trace as st\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5MGs4qVpuec"
      },
      "source": [
        "#Defining Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IJDIhXSnoFIt"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataroot='datasets'\n",
        "batchSize=1 # 메모리사이즈\n",
        "loadSize=286\n",
        "fineSize=256\n",
        "input_nc=3\n",
        "output_nc=3\n",
        "ntest=float(\"inf\")\n",
        "results_dir='./results/'\n",
        "aspect_ratio=1.0\n",
        "how_many=200\n",
        "ngf=64\n",
        "ndf=64\n",
        "which_model_netD='basic'\n",
        "which_model_netG='unet_256'\n",
        "n_layers_D=3\n",
        "gpu_ids=[0]\n",
        "name='Trained_Model'\n",
        "dataset_mode='aligned'\n",
        "model='pix2pix'\n",
        "which_direction='BtoA'\n",
        "nThreads=2\n",
        "checkpoints_dir='./checkpoints'\n",
        "norm='batch'\n",
        "serial_batches= False\n",
        "display_winsize=256\n",
        "display_id=0\n",
        "display_port=8097\n",
        "display_single_pane_ncols=0\n",
        "identity=0.0\n",
        "no_dropout=False\n",
        "max_dataset_size=float(\"inf\")\n",
        "resize_or_crop='resize_and_crop'\n",
        "no_flip=False\n",
        "use_spp=True\n",
        "display_freq=50\n",
        "print_freq=100\n",
        "save_latest_freq=800\n",
        "save_epoch_freq=200\n",
        "continue_train=False\n",
        "phase='train'\n",
        "which_epoch='2800'\n",
        "niter=200\n",
        "niter_decay=800\n",
        "#Total epochs = nitr+nitr_decay\n",
        "beta1=0.5\n",
        "lr=0.0002\n",
        "no_lsgan=True\n",
        "lambda_A=100\n",
        "lambda_B=10.0\n",
        "pool_size=50\n",
        "no_html=False\n",
        "isTrain = True\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4RRXMSN8rg6"
      },
      "source": [
        "#defining Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BO63thvI8m-P"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    model = 'pix2pix'\n",
        "    dataset_mode='aligned'\n",
        "    print(model)\n",
        "\n",
        "    if model == 'pix2pix':\n",
        "        assert(dataset_mode == 'aligned')\n",
        "        model = Pix2PixModel()\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Model [%s] not recognized.\" % model)\n",
        "    model.initialize()\n",
        "    print(\"model [%s] was created\" % (model.name()))\n",
        "    return model\n",
        "\n",
        "def CreateDataLoader():\n",
        "    data_loader = CustomDatasetDataLoader()\n",
        "    print(data_loader.name())\n",
        "    data_loader.initialize()\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "\n",
        "class Visualizer():\n",
        "    def __init__(self):\n",
        "        # self.opt = opt\n",
        "        self.display_id = display_id\n",
        "        self.use_html = isTrain and not no_html\n",
        "        self.win_size = display_winsize\n",
        "        self.name = name\n",
        "        if self.display_id > 0:\n",
        "            import visdom\n",
        "            self.vis = visdom.Visdom(port = display_port)\n",
        "            self.display_single_pane_ncols = display_single_pane_ncols\n",
        "\n",
        "        if self.use_html:\n",
        "            self.web_dir = os.path.join(checkpoints_dir, name, 'web')\n",
        "            self.img_dir = os.path.join(self.web_dir, 'images')\n",
        "            print('create web directory %s...' % self.web_dir)\n",
        "            util.mkdirs([self.web_dir, self.img_dir])\n",
        "        self.log_name = os.path.join(checkpoints_dir, name, 'loss_log.txt')\n",
        "        with open(self.log_name, \"a\") as log_file:\n",
        "            now = time.strftime(\"%c\")\n",
        "            log_file.write('================ Training Loss (%s) ================\\n' % now)\n",
        "\n",
        "    # |visuals|: dictionary of images to display or save\n",
        "    def display_current_results(self, visuals, epoch):\n",
        "        if self.display_id > 0: # show images in the browser\n",
        "            if self.display_single_pane_ncols > 0:\n",
        "                h, w = next(iter(visuals.values())).shape[:2]\n",
        "                table_css = \"\"\"<style>\n",
        "    table {border-collapse: separate; border-spacing:4px; white-space:nowrap; text-align:center}\n",
        "    table td {width: %dpx; height: %dpx; padding: 4px; outline: 4px solid black}\n",
        "</style>\"\"\" % (w, h)\n",
        "                ncols = self.display_single_pane_ncols\n",
        "                title = self.name\n",
        "                label_html = ''\n",
        "                label_html_row = ''\n",
        "                nrows = int(np.ceil(len(visuals.items()) / ncols))\n",
        "                images = []\n",
        "                idx = 0\n",
        "                for label, image_numpy in visuals.items():\n",
        "                    label_html_row += '<td>%s</td>' % label\n",
        "                    images.append(image_numpy.transpose([2, 0, 1]))\n",
        "                    idx += 1\n",
        "                    if idx % ncols == 0:\n",
        "                        label_html += '<tr>%s</tr>' % label_html_row\n",
        "                        label_html_row = ''\n",
        "                white_image = np.ones_like(image_numpy.transpose([2, 0, 1]))*255\n",
        "                while idx % ncols != 0:\n",
        "                    images.append(white_image)\n",
        "                    label_html_row += '<td></td>'\n",
        "                    idx += 1\n",
        "                if label_html_row != '':\n",
        "                    label_html += '<tr>%s</tr>' % label_html_row\n",
        "                # pane col = image row\n",
        "                self.vis.images(images, nrow=ncols, win=self.display_id + 1,\n",
        "                                padding=2, opts=dict(title=title + ' images'))\n",
        "                label_html = '<table>%s</table>' % label_html\n",
        "                self.vis.text(table_css + label_html, win = self.display_id + 2,\n",
        "                              opts=dict(title=title + ' labels'))\n",
        "            else:\n",
        "                idx = 1\n",
        "                for label, image_numpy in visuals.items():\n",
        "                    #image_numpy = np.flipud(image_numpy)\n",
        "                    self.vis.image(image_numpy.transpose([2,0,1]), opts=dict(title=label),\n",
        "                                       win=self.display_id + idx)\n",
        "                    idx += 1\n",
        "\n",
        "        if self.use_html: # save images to a html file\n",
        "            for label, image_numpy in visuals.items():\n",
        "                img_path = os.path.join(self.img_dir, 'epoch%.3d_%s.png' % (epoch, label))\n",
        "                util.save_image(image_numpy, img_path)\n",
        "            # update website\n",
        "            webpage = html.HTML(self.web_dir, 'Experiment name = %s' % self.name, reflesh=1)\n",
        "            for n in range(epoch, 0, -1):\n",
        "                webpage.add_header('epoch [%d]' % n)\n",
        "                ims = []\n",
        "                txts = []\n",
        "                links = []\n",
        "\n",
        "                for label, image_numpy in visuals.items():\n",
        "                    img_path = 'epoch%.3d_%s.png' % (n, label)\n",
        "                    ims.append(img_path)\n",
        "                    txts.append(label)\n",
        "                    links.append(img_path)\n",
        "                webpage.add_images(ims, txts, links, width=self.win_size)\n",
        "            webpage.save()\n",
        "\n",
        "    # errors: dictionary of error labels and values\n",
        "    def plot_current_errors(self, epoch, counter_ratio, opt, errors):\n",
        "        if not hasattr(self, 'plot_data'):\n",
        "            self.plot_data = {'X':[],'Y':[], 'legend':list(errors.keys())}\n",
        "        self.plot_data['X'].append(epoch + counter_ratio)\n",
        "        self.plot_data['Y'].append([errors[k] for k in self.plot_data['legend']])\n",
        "        self.vis.line(\n",
        "            X=np.stack([np.array(self.plot_data['X'])]*len(self.plot_data['legend']),1),\n",
        "            Y=np.array(self.plot_data['Y']),\n",
        "            opts={\n",
        "                'title': self.name + ' loss over time',\n",
        "                'legend': self.plot_data['legend'],\n",
        "                'xlabel': 'epoch',\n",
        "                'ylabel': 'loss'},\n",
        "            win=self.display_id)\n",
        "\n",
        "    # errors: same format as |errors| of plotCurrentErrors\n",
        "    def print_current_errors(self, epoch, i, errors, t):\n",
        "        message = '(epoch: %d, iters: %d, time: %.3f) ' % (epoch, i, t)\n",
        "        for k, v in errors.items():\n",
        "            message += '%s: %.3f ' % (k, v)\n",
        "\n",
        "        print(message)\n",
        "        with open(self.log_name, \"a\") as log_file:\n",
        "            log_file.write('%s\\n' % message)\n",
        "\n",
        "    # save image to the disk\n",
        "\n",
        "    def save_images(self, webpage, visuals, image_path):\n",
        "        id_d=0\n",
        "        image_dir = webpage.get_image_dir()\n",
        "        short_path = ntpath.basename(image_path[0])\n",
        "        name = os.path.splitext(short_path)[0]\n",
        "\n",
        "        webpage.add_header(name)\n",
        "        ims = []\n",
        "        txts = []\n",
        "        links = []\n",
        "        for label, image_numpy in visuals.items():\n",
        "            image_name = '%s_%s.png' % (name, label)\n",
        "            save_path = os.path.join(image_dir, image_name)\n",
        "            util.save_image(image_numpy, save_path)\n",
        "            if id_d==3:\n",
        "              figure(figsize=(8, 6), dpi=80)\n",
        "              plt.imshow(image_numpy, interpolation='nearest')\n",
        "              plt.title('Generated Pedestrian')\n",
        "              plt.show()\n",
        "\n",
        "            ims.append(image_name)\n",
        "            txts.append(label)\n",
        "            links.append(image_name)\n",
        "            id_d+=1\n",
        "        webpage.add_images(ims, txts, links, width=self.win_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtPlOP64WO2j"
      },
      "source": [
        "#Defining DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7eRSKK3NAOO7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class BaseDataset(data.Dataset):\n",
        "    def __init__(self):\n",
        "        super(BaseDataset, self).__init__()\n",
        "\n",
        "    def name(self):\n",
        "        return 'BaseDataset'\n",
        "\n",
        "    def initialize(self):\n",
        "        pass\n",
        "\n",
        "def get_transform():\n",
        "    transform_list = []\n",
        "    if resize_or_crop == 'resize_and_crop':\n",
        "        osize = [loadSize, loadSize]\n",
        "        transform_list.append(transforms.Scale(osize, Image.BICUBIC))\n",
        "        transform_list.append(transforms.RandomCrop(fineSize))\n",
        "    elif resize_or_crop == 'crop':\n",
        "        transform_list.append(transforms.RandomCrop(fineSize))\n",
        "    elif resize_or_crop == 'scale_width':\n",
        "        transform_list.append(transforms.Lambda(\n",
        "            lambda img: __scale_width(img, fineSize)))\n",
        "    elif resize_or_crop == 'scale_width_and_crop':\n",
        "        transform_list.append(transforms.Lambda(\n",
        "            lambda img: __scale_width(img, loadSize)))\n",
        "        transform_list.append(transforms.RandomCrop(fineSize))\n",
        "\n",
        "    if isTrain and not no_flip:\n",
        "        transform_list.append(transforms.RandomHorizontalFlip())\n",
        "\n",
        "    transform_list += [transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                            (0.5, 0.5, 0.5))]\n",
        "    return transforms.Compose(transform_list)\n",
        "\n",
        "def __scale_width(img, target_width):\n",
        "    ow, oh = img.size\n",
        "    if (ow == target_width):\n",
        "        return img\n",
        "    w = target_width\n",
        "    h = int(target_width * oh / ow)\n",
        "    return img.resize((w, h), Image.BICUBIC)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AlignedDataset(BaseDataset): #noise와 원본데이터필요해야해서?\n",
        "    def initialize(self): #노이즈는 변하지 않는다.\n",
        "        # self.opt = opt\n",
        "        self.root = dataroot\n",
        "        self.fineSize=fineSize\n",
        "        self.loadSize=loadSize\n",
        "        self.no_flip=no_flip\n",
        "        self.dir_AB = os.path.join(dataroot, 'images', phase)\n",
        "        self.dir_bbox = os.path.join(dataroot, 'bbox', phase)\n",
        "\n",
        "        #self.AB_paths, self.bbox_paths = sorted(make_dataset(self.dir_AB, self.dir_bbox))\n",
        "        self.AB_paths, self.bbox_paths = make_dataset(self.dir_AB, self.dir_bbox)\n",
        "        self.AB_paths = sorted(self.AB_paths)\n",
        "        self.bbox_paths = sorted(self.bbox_paths)\n",
        "\n",
        "        assert(resize_or_crop == 'resize_and_crop')\n",
        "\n",
        "        transform_list = [transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                               (0.5, 0.5, 0.5))]\n",
        "\n",
        "        self.transform = transforms.Compose(transform_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        AB_path = self.AB_paths[index]\n",
        "        #print(AB_path)\n",
        "        bbox_path = self.bbox_paths[index]\n",
        "        #print(bbox_path)\n",
        "\n",
        "        w_total = self.loadSize * 2\n",
        "        w = int(w_total / 2)\n",
        "        h = self.loadSize\n",
        "        w_offset = random.randint(0, max(0, w - self.fineSize - 1))\n",
        "        h_offset = random.randint(0, max(0, h - self.fineSize - 1))\n",
        "\n",
        "        bbox = json.load(open(bbox_path))\n",
        "        #bbox = [bbox['y'], bbox['x'], bbox['w'], bbox['h']]\n",
        "        #print(bbox['y'], bbox['x'], bbox['w'], bbox['h'])\n",
        "        bbox_x = max(int((bbox['x']/self.fineSize)*self.loadSize), 0)\n",
        "        bbox_y = max(int((bbox['y']/self.fineSize)*self.loadSize), 0)\n",
        "        bbox_w = max(int((bbox['w']/self.fineSize)*self.loadSize), 0)\n",
        "        bbox_h = max(int((bbox['h']/self.fineSize)*self.loadSize), 0)\n",
        "\n",
        "        if bbox_y <= h_offset or bbox_x <= w_offset:\n",
        "            AB = Image.open(AB_path).convert('RGB')\n",
        "            AB = AB.resize((self.fineSize * 2, self.fineSize), Image.BICUBIC)\n",
        "            AB = self.transform(AB)\n",
        "            A = AB[:, :self.fineSize,\n",
        "               :self.fineSize]\n",
        "            B = AB[:, :self.fineSize,\n",
        "                self.fineSize:2*self.fineSize]\n",
        "            bbox = [bbox['y'], bbox['x'], bbox['w'], bbox['h']]\n",
        "        else:\n",
        "            AB = Image.open(AB_path).convert('RGB')\n",
        "            AB = AB.resize((self.loadSize * 2, self.loadSize), Image.BICUBIC)\n",
        "            AB = self.transform(AB)\n",
        "            # 아래는 random crop\n",
        "            A = AB[:, h_offset:h_offset + self.fineSize,\n",
        "               w_offset:w_offset + self.fineSize]\n",
        "            B = AB[:, h_offset:h_offset + self.fineSize,\n",
        "                w + w_offset:w + w_offset + self.fineSize]\n",
        "            bbox = [bbox_y-h_offset, bbox_x-w_offset, bbox_w, bbox_h]\n",
        "        # print('haha')\n",
        "        # print(bbox)\n",
        "\n",
        "\n",
        "        if (not self.no_flip) and random.random() < 0.5:\n",
        "            idx = [i for i in range(A.size(2) - 1, -1, -1)]\n",
        "            idx = torch.LongTensor(idx)\n",
        "            A = A.index_select(2, idx)\n",
        "            B = B.index_select(2, idx)\n",
        "            #print A.size(2)\n",
        "            bbox = [bbox[0], A.size(2) - bbox[2], A.size(2) - bbox[1], bbox[3]]\n",
        "        # print('hehe')\n",
        "        # print(bbox)\n",
        "        #print(A.size())\n",
        "        return {'A': A, 'B': B, 'bbox': bbox,\n",
        "                'A_paths': AB_path, 'B_paths': AB_path}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.AB_paths)\n",
        "\n",
        "    def name(self):\n",
        "        return 'AlignedDataset'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def CreateDataset():\n",
        "    dataset = None\n",
        "    if dataset_mode == 'aligned':\n",
        "\n",
        "        dataset = AlignedDataset()\n",
        "    elif dataset_mode == 'unaligned':\n",
        "        from data.unaligned_dataset import UnalignedDataset\n",
        "        dataset = UnalignedDataset()\n",
        "    elif dataset_mode == 'single':\n",
        "        from data.single_dataset import SingleDataset\n",
        "        dataset = SingleDataset()\n",
        "    else:\n",
        "        raise ValueError(\"Dataset [%s] not recognized.\" % dataset_mode)\n",
        "\n",
        "    print(\"dataset [%s] was created\" % (dataset.name()))\n",
        "    dataset.initialize()\n",
        "    return dataset\n",
        "\n",
        "\n",
        "class CustomDatasetDataLoader(BaseDataLoader):\n",
        "    def name(self):\n",
        "        return 'CustomDatasetDataLoader'\n",
        "\n",
        "    def initialize(self):\n",
        "        BaseDataLoader.initialize(self)\n",
        "        self.dataset = CreateDataset()\n",
        "        self.max_dataset_size=max_dataset_size\n",
        "        self.dataloader = torch.utils.data.DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=batchSize,\n",
        "            shuffle=not serial_batches,\n",
        "            num_workers=int(nThreads))\n",
        "\n",
        "    def load_data(self):\n",
        "        return self.dataloader\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.dataset), self.max_dataset_size)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v3CF8MC76v4"
      },
      "source": [
        "#Defining  Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "D1QG7zrD7LjN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class BaseModel():\n",
        "    def name(self):\n",
        "        return 'BaseModel'\n",
        "\n",
        "    def initialize(self):\n",
        "        # self.opt = opt\n",
        "        self.gpu_ids = gpu_ids\n",
        "        self.isTrain = isTrain\n",
        "        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n",
        "        self.save_dir = os.path.join(checkpoints_dir, name)\n",
        "\n",
        "    def set_input(self, input):\n",
        "        self.input = input\n",
        "\n",
        "    def forward(self):\n",
        "        pass\n",
        "\n",
        "    # used in test time, no backprop\n",
        "    def test(self):\n",
        "        pass\n",
        "\n",
        "    def get_image_paths(self):\n",
        "        pass\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        pass\n",
        "\n",
        "    def get_current_visuals(self):\n",
        "        return self.input\n",
        "\n",
        "    def get_current_errors(self):\n",
        "        return {}\n",
        "\n",
        "    def save(self, label):\n",
        "        pass\n",
        "\n",
        "    # helper saving function that can be used by subclasses\n",
        "    def save_network(self, network, network_label, epoch_label, gpu_ids):\n",
        "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
        "        save_path = os.path.join(self.save_dir, save_filename)\n",
        "        torch.save(network.cpu().state_dict(), save_path)\n",
        "        if len(gpu_ids) and torch.cuda.is_available():\n",
        "            network.cuda(device=gpu_ids[0])\n",
        "\n",
        "    # helper loading function that can be used by subclasses\n",
        "    def load_network(self, network, network_label, epoch_label):\n",
        "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
        "        save_path = os.path.join(self.save_dir, save_filename)\n",
        "        network.load_state_dict(torch.load(save_path))\n",
        "\n",
        "    def update_learning_rate():\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Pix2PixModel(BaseModel):\n",
        "    def name(self):\n",
        "        return 'Pix2PixModel'\n",
        "\n",
        "    def initialize(self):\n",
        "        BaseModel.initialize(self)\n",
        "        # self.opt = opt\n",
        "        self.lr=lr\n",
        "        self.niter_decay=niter_decay\n",
        "        self.isTrain = isTrain\n",
        "        self.which_direction=which_direction\n",
        "        # define tensors\n",
        "        self.lambda_A=lambda_A\n",
        "        self.input_A = self.Tensor(batchSize, input_nc,\n",
        "                                   fineSize, fineSize)\n",
        "        self.input_B = self.Tensor(batchSize, output_nc,\n",
        "                                   fineSize, fineSize)\n",
        "\n",
        "        transform_list = [transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                               (0.5, 0.5, 0.5))]\n",
        "\n",
        "        self.transform = transforms.Compose(transform_list)\n",
        "\n",
        "        # load/define networks\n",
        "        self.netG = networks.define_G(input_nc, output_nc, ngf,\n",
        "                                      which_model_netG, norm, not no_dropout, self.gpu_ids)\n",
        "        if self.isTrain:\n",
        "            use_sigmoid = no_lsgan\n",
        "            self.netD_image = networks.define_image_D(input_nc + output_nc, ndf,\n",
        "                                          which_model_netD,\n",
        "                                          n_layers_D, norm, use_sigmoid, self.gpu_ids)\n",
        "            use_sigmoid = not no_lsgan\n",
        "            self.netD_person = networks.define_person_D(input_nc, ndf, use_sigmoid, self.gpu_ids)\n",
        "\n",
        "        if not self.isTrain or continue_train:\n",
        "            self.load_network(self.netG, 'G', which_epoch)\n",
        "            if self.isTrain:\n",
        "                self.load_network(self.netD_image, 'D_image', which_epoch)\n",
        "                self.load_network(self.netD_person, 'D_person', which_epoch)\n",
        "\n",
        "        if self.isTrain:\n",
        "            self.fake_AB_pool = ImagePool(pool_size)\n",
        "            self.old_lr = lr\n",
        "            # define loss functions\n",
        "            #print('haha'+ str(opt.no_lsgan))\n",
        "            # self.criterionGAN = networks.GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n",
        "            self.criterionGAN_image = networks.GANLoss(use_lsgan=not no_lsgan, tensor=self.Tensor)\n",
        "            self.criterionGAN_person = networks.GANLoss(use_lsgan=no_lsgan, tensor=self.Tensor)\n",
        "            self.criterionL1 = torch.nn.L1Loss()\n",
        "\n",
        "            # initialize optimizers\n",
        "            self.optimizer_G = torch.optim.Adam(self.netG.parameters(),\n",
        "                                                lr=lr, betas=(beta1, 0.999))\n",
        "            self.optimizer_D_image = torch.optim.Adam(self.netD_image.parameters(),\n",
        "                                                lr=lr, betas=(beta1, 0.999))\n",
        "            self.optimizer_D_person = torch.optim.Adam(self.netD_person.parameters(),\n",
        "                                                lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "        print('---------- Networks initialized -------------')\n",
        "        networks.print_network(self.netG)\n",
        "        if self.isTrain:\n",
        "            networks.print_network(self.netD_image)\n",
        "            networks.print_network(self.netD_person)\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "    def set_input(self, input):\n",
        "        AtoB = self.which_direction == 'AtoB'\n",
        "        input_A = input['A' if AtoB else 'B']\n",
        "        input_B = input['B' if AtoB else 'A']\n",
        "        #print(input_A.size())\n",
        "        self.bbox = input['bbox']\n",
        "        self.input_A.resize_(input_A.size()).copy_(input_A)\n",
        "        self.input_B.resize_(input_B.size()).copy_(input_B)\n",
        "\n",
        "        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n",
        "\n",
        "    def forward(self):\n",
        "        self.real_A = Variable(self.input_A)\n",
        "        self.fake_B = self.netG.forward(self.real_A)\n",
        "        self.real_B = Variable(self.input_B)\n",
        "\n",
        "        y,x,w,h = self.bbox\n",
        "        self.person_crop_real = self.real_B[:,:,y[0]:h[0],x[0]:w[0]]\n",
        "        self.person_crop_fake = self.fake_B[:,:,y[0]:h[0],x[0]:w[0]]\n",
        "\n",
        "    # no backprop gradients\n",
        "    def test(self):\n",
        "        self.real_A = Variable(self.input_A, volatile=True)\n",
        "        self.fake_B = self.netG.forward(self.real_A)\n",
        "        self.real_B = Variable(self.input_B, volatile=True)\n",
        "\n",
        "        y,x,w,h = self.bbox\n",
        "        self.person_crop_real = self.real_B[:,:,y[0]:h[0],x[0]:w[0]]\n",
        "        self.person_crop_fake = self.fake_B[:,:,y[0]:h[0],x[0]:w[0]]\n",
        "\n",
        "    # get image paths\n",
        "    def get_image_paths(self):\n",
        "        return self.image_paths\n",
        "\n",
        "    def backward_D_image(self):\n",
        "        # Fake\n",
        "        # stop backprop to the generator by detaching fake_B\n",
        "        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1))\n",
        "        self.pred_fake = self.netD_image.forward(fake_AB.detach())\n",
        "        # self.loss_D_image_fake = self.criterionGAN(self.pred_fake, False)\n",
        "        self.loss_D_image_fake = self.criterionGAN_image(self.pred_fake, False)\n",
        "\n",
        "        # Real\n",
        "        real_AB = torch.cat((self.real_A, self.real_B), 1)\n",
        "        self.pred_real = self.netD_image.forward(real_AB)\n",
        "        # self.loss_D_image_real = self.criterionGAN(self.pred_real, True)\n",
        "        self.loss_D_image_real = self.criterionGAN_image(self.pred_real, True)\n",
        "\n",
        "        # Combined loss\n",
        "        self.loss_D_image = (self.loss_D_image_fake + self.loss_D_image_real) * 0.5\n",
        "\n",
        "        self.loss_D_image.backward()\n",
        "\n",
        "    def backward_D_person(self):\n",
        "        #Fake\n",
        "        self.person_fake = self.netD_person.forward(self.person_crop_fake)\n",
        "        # self.loss_D_person_fake = self.criterionGAN(self.person_fake, False)\n",
        "        self.loss_D_person_fake = self.criterionGAN_person(self.person_fake, False)\n",
        "\n",
        "        #Real\n",
        "        self.person_real = self.netD_person.forward(self.person_crop_real)\n",
        "        # self.loss_D_person_real = self.criterionGAN(self.person_real, True)\n",
        "        self.loss_D_person_real = self.criterionGAN_person(self.person_real, True)\n",
        "\n",
        "        #Combine loss\n",
        "        self.loss_D_person = (self.loss_D_person_fake + self.loss_D_person_real) * 0.5\n",
        "        self.loss_D_person.backward()\n",
        "\n",
        "\n",
        "    def backward_G(self):\n",
        "        # First, G(A) should fake the discriminator1 and discriminator1\n",
        "        # discriminator1\n",
        "        fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n",
        "        pred_fake_image = self.netD_image.forward(fake_AB)\n",
        "        # self.loss_G_GAN_image = self.criterionGAN(pred_fake_image, True)\n",
        "        self.loss_G_GAN_image = self.criterionGAN_image(pred_fake_image, True)\n",
        "        # Second, G(A) = B\n",
        "        self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B) * self.lambda_A\n",
        "        #self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B)\n",
        "\n",
        "        pred_fake_person = self.netD_person.forward(self.person_crop_fake)\n",
        "        # self.loss_G_GAN_person = self.criterionGAN(pred_fake_person, True)\n",
        "        self.loss_G_GAN_person = self.criterionGAN_person(pred_fake_person, True)\n",
        "\n",
        "        #self.loss_G_L1_person = self.criterionL1(self.person_crop_fake, self.person_crop_real)\n",
        "\n",
        "\n",
        "        self.loss_G = self.loss_G_GAN_image + self.loss_G_L1 + self.loss_G_GAN_person\n",
        "\n",
        "        self.loss_G.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def optimize_parameters(self, only_d):\n",
        "\n",
        "        self.forward()\n",
        "        self.optimizer_D_image.zero_grad()\n",
        "        self.backward_D_image()\n",
        "        self.optimizer_D_image.step()\n",
        "\n",
        "        self.forward()\n",
        "        self.optimizer_D_person.zero_grad()\n",
        "        self.backward_D_person()\n",
        "        self.optimizer_D_person.step()\n",
        "\n",
        "        if only_d == False:\n",
        "            self.forward()\n",
        "            self.optimizer_G.zero_grad()\n",
        "            self.backward_G()\n",
        "            self.optimizer_G.step()\n",
        "\n",
        "    def get_current_errors(self):\n",
        "        return OrderedDict([('G_GAN_image', self.loss_G_GAN_image.data),\n",
        "                            ('G_GAN_person', self.loss_G_GAN_person.data),\n",
        "                            ('G_L1', self.loss_G_L1.data),\n",
        "                            #('G_L1_person', self.loss_G_L1_person.data[0]),\n",
        "                            ('D_image_real', self.loss_D_image_real.data),\n",
        "                            ('D_image_fake', self.loss_D_image_fake.data),\n",
        "                            ('D_person_real', self.loss_D_person_real.data),\n",
        "                            ('D_person_fake', self.loss_D_person_fake.data)\n",
        "                            ])\n",
        "\n",
        "    def get_current_visuals(self):\n",
        "        real_A = util.tensor2im(self.real_A.data)\n",
        "        fake_B = util.tensor2im(self.fake_B.data)\n",
        "        real_B = util.tensor2im(self.real_B.data)\n",
        "        D2_fake = util.tensor2im(self.person_crop_fake.data)\n",
        "        D2_real = util.tensor2im(self.person_crop_real.data)\n",
        "        y,x,w,h = self.bbox\n",
        "        display = deepcopy(real_A)\n",
        "        #print(display.shape)\n",
        "        display[y[0]:h[0],x[0]:w[0],:] = D2_fake\n",
        "        return OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('real_B', real_B), ('display', display), ('D2_fake',D2_fake),('D2_real',D2_real)])\n",
        "        #return OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('real_B', real_B)])\n",
        "\n",
        "    def save(self, label):\n",
        "        self.save_network(self.netG, 'G', label, self.gpu_ids)\n",
        "        self.save_network(self.netD_image, 'D_image', label, self.gpu_ids)\n",
        "        self.save_network(self.netD_person, 'D_person', label, self.gpu_ids)\n",
        "\n",
        "    def update_learning_rate(self):\n",
        "        lrd = self.lr / self.niter_decay\n",
        "        lr = self.old_lr - lrd\n",
        "        for param_group in self.optimizer_D_image.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        for param_group in self.optimizer_D_person.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        for param_group in self.optimizer_G.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        print('update learning rate: %f -> %f' % (self.old_lr, lr))\n",
        "        self.old_lr = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fIdIKFxQ7Lt"
      },
      "source": [
        "#Downloading PreTrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_X6idFJQ-jb",
        "outputId": "15f6d9ff-ea4b-42eb-c442-fef1c42132e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading PreTrained Model\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/u/0/uc?id=1-fncH9lKoM-YKwD8DEomPQjUv89LsX8r\n",
            "From (redirected): https://drive.google.com/uc?id=1-fncH9lKoM-YKwD8DEomPQjUv89LsX8r&confirm=t&uuid=217a172c-8a2d-40b4-9893-58932e0c7cf2\n",
            "To: /content/gan/Trained_Model.zip\n",
            "100% 445M/445M [00:06<00:00, 68.5MB/s]\n",
            "Archive:  Trained_Model.zip\n",
            "  inflating: checkpoints/Trained_Model/loss_log.txt  \n",
            "  inflating: checkpoints/Trained_Model/2800_net_D_image.pth  \n",
            "  inflating: checkpoints/Trained_Model/2800_net_D_person.pth  \n",
            "  inflating: checkpoints/Trained_Model/latest_net_D_image.pth  \n",
            "  inflating: checkpoints/Trained_Model/latest_net_D_person.pth  \n",
            "  inflating: checkpoints/Trained_Model/latest_net_G.pth  \n",
            "  inflating: checkpoints/Trained_Model/2800_net_G.pth  \n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(checkpoints_dir) is False:\n",
        "  print(\"Downloading PreTrained Model\")\n",
        "  !mkdir checkpoints\n",
        "  !gdown https://drive.google.com/u/0/uc?id=1-fncH9lKoM-YKwD8DEomPQjUv89LsX8r&export=download\n",
        "  !unzip Trained_Model.zip  -d checkpoints\n",
        "else:\n",
        "  print('Model Already Present')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtFBc8y9W1H-"
      },
      "source": [
        "#Training Script"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZcurYtFTZQQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tJq50AOoFLG",
        "outputId": "16a2469c-0b7c-4363-e405-38d38a648319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 6\n",
            "pix2pix\n",
            "False\n",
            "True\n",
            "---------- Networks initialized -------------\n",
            "UnetGenerator(\n",
            "  (model): UnetSkipConnectionBlock(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): UnetSkipConnectionBlock(\n",
            "        (model): Sequential(\n",
            "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): UnetSkipConnectionBlock(\n",
            "            (model): Sequential(\n",
            "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "              (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (3): UnetSkipConnectionBlock(\n",
            "                (model): Sequential(\n",
            "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                  (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                  (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (3): UnetSkipConnectionBlock(\n",
            "                    (model): Sequential(\n",
            "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                      (3): UnetSkipConnectionBlock(\n",
            "                        (model): Sequential(\n",
            "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                          (3): UnetSkipConnectionBlock(\n",
            "                            (model): Sequential(\n",
            "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                              (3): UnetSkipConnectionBlock(\n",
            "                                (model): Sequential(\n",
            "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                  (2): ReLU(inplace=True)\n",
            "                                  (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                  (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                                )\n",
            "                              )\n",
            "                              (4): ReLU(inplace=True)\n",
            "                              (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                              (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                              (7): Dropout(p=0.5, inplace=False)\n",
            "                            )\n",
            "                          )\n",
            "                          (4): ReLU(inplace=True)\n",
            "                          (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                          (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                          (7): Dropout(p=0.5, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (4): ReLU(inplace=True)\n",
            "                      (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                      (7): Dropout(p=0.5, inplace=False)\n",
            "                    )\n",
            "                  )\n",
            "                  (4): ReLU(inplace=True)\n",
            "                  (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                )\n",
            "              )\n",
            "              (4): ReLU(inplace=True)\n",
            "              (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "          (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (4): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 54419459\n",
            "NLayerDiscriminator(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 2769601\n",
            "SPP_NET(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (LReLU1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (BN1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LReLU2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (BN2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LReLU3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (BN3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (LReLU4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (conv5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            ")\n",
            "Total number of parameters: 2765568\n",
            "-----------------------------------------------\n",
            "model [Pix2PixModel] was created\n",
            "create web directory ./checkpoints/Trained_Model/web...\n",
            "End of epoch 1 / 1000 \t Time Taken: 3 sec\n",
            "End of epoch 2 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 3 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 4 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 5 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 6 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 7 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 8 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 9 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 10 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 11 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 12 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 13 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 14 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 15 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 16 / 1000 \t Time Taken: 2 sec\n",
            "(epoch: 17, iters: 4, time: 0.577) G_GAN_image: 0.751 G_GAN_person: 1.549 G_L1: 12.627 D_image_real: 0.471 D_image_fake: 0.282 D_person_real: 0.766 D_person_fake: 0.462 \n",
            "End of epoch 17 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 18 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 19 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 20 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 21 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 22 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 23 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 24 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 25 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 26 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 27 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 28 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 29 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 30 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 31 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 32 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 33 / 1000 \t Time Taken: 2 sec\n",
            "(epoch: 34, iters: 2, time: 0.914) G_GAN_image: 1.301 G_GAN_person: 1.175 G_L1: 7.905 D_image_real: 0.574 D_image_fake: 0.050 D_person_real: 0.739 D_person_fake: 0.124 \n",
            "End of epoch 34 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 35 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 36 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 37 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 38 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 39 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 40 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 41 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 42 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 43 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 44 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 45 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 46 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 47 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 48 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 49 / 1000 \t Time Taken: 1 sec\n",
            "(epoch: 50, iters: 6, time: 0.597) G_GAN_image: 1.872 G_GAN_person: 0.834 G_L1: 10.473 D_image_real: 0.118 D_image_fake: 0.926 D_person_real: 0.094 D_person_fake: 0.035 \n",
            "End of epoch 50 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 51 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 52 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 53 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 54 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 55 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 56 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 57 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 58 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 59 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 60 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 61 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 62 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 63 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 64 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 65 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 66 / 1000 \t Time Taken: 2 sec\n",
            "(epoch: 67, iters: 4, time: 0.589) G_GAN_image: 1.590 G_GAN_person: 0.583 G_L1: 8.360 D_image_real: 0.173 D_image_fake: 0.678 D_person_real: 0.135 D_person_fake: 0.068 \n",
            "End of epoch 67 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 68 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 69 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 70 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 71 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 72 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 73 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 74 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 75 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 76 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 77 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 78 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 79 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 80 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 81 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 82 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 83 / 1000 \t Time Taken: 2 sec\n",
            "(epoch: 84, iters: 2, time: 0.646) G_GAN_image: 2.658 G_GAN_person: 0.886 G_L1: 9.428 D_image_real: 0.076 D_image_fake: 0.446 D_person_real: 0.054 D_person_fake: 0.109 \n",
            "End of epoch 84 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 85 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 86 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 87 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 88 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 89 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 90 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 91 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 92 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 93 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 94 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 95 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 96 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 97 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 98 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 99 / 1000 \t Time Taken: 1 sec\n",
            "(epoch: 100, iters: 6, time: 1.069) G_GAN_image: 0.616 G_GAN_person: 0.732 G_L1: 8.584 D_image_real: 0.286 D_image_fake: 0.157 D_person_real: 0.201 D_person_fake: 0.097 \n",
            "End of epoch 100 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 101 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 102 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 103 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 104 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 105 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 106 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 107 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 108 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 109 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 110 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 111 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 112 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 113 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 114 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 115 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 116 / 1000 \t Time Taken: 1 sec\n",
            "(epoch: 117, iters: 4, time: 0.709) G_GAN_image: 0.782 G_GAN_person: 0.462 G_L1: 8.261 D_image_real: 0.735 D_image_fake: 0.703 D_person_real: 0.133 D_person_fake: 0.297 \n",
            "End of epoch 117 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 118 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 119 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 120 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 121 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 122 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 123 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 124 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 125 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 126 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 127 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 128 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 129 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 130 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 131 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 132 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 133 / 1000 \t Time Taken: 1 sec\n",
            "(epoch: 134, iters: 2, time: 0.546) G_GAN_image: 2.626 G_GAN_person: 1.006 G_L1: 5.046 D_image_real: 0.124 D_image_fake: 1.726 D_person_real: 0.059 D_person_fake: 0.091 \n",
            "saving the latest model (epoch 134, total_steps 800)\n",
            "End of epoch 134 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 135 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 136 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 137 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 138 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 139 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 140 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 141 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 142 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 143 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 144 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 145 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 146 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 147 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 148 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 149 / 1000 \t Time Taken: 1 sec\n",
            "(epoch: 150, iters: 6, time: 0.828) G_GAN_image: 1.057 G_GAN_person: 0.584 G_L1: 7.402 D_image_real: 0.457 D_image_fake: 0.644 D_person_real: 0.280 D_person_fake: 0.093 \n",
            "End of epoch 150 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 151 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 152 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 153 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 154 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 155 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 156 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 157 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 158 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 159 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 160 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 161 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 162 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 163 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 164 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 165 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 166 / 1000 \t Time Taken: 1 sec\n",
            "(epoch: 167, iters: 4, time: 0.876) G_GAN_image: 1.160 G_GAN_person: 0.764 G_L1: 4.696 D_image_real: 0.365 D_image_fake: 0.408 D_person_real: 0.289 D_person_fake: 0.037 \n",
            "End of epoch 167 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 168 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 169 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 170 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 171 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 172 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 173 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 174 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 175 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 176 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 177 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 178 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 179 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 180 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 181 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 182 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 183 / 1000 \t Time Taken: 1 sec\n",
            "(epoch: 184, iters: 2, time: 0.611) G_GAN_image: 0.508 G_GAN_person: 0.821 G_L1: 5.306 D_image_real: 0.990 D_image_fake: 0.050 D_person_real: 0.039 D_person_fake: 0.132 \n",
            "End of epoch 184 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 185 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 186 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 187 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 188 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 189 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 190 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 191 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 192 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 193 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 194 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 195 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 196 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 197 / 1000 \t Time Taken: 2 sec\n",
            "End of epoch 198 / 1000 \t Time Taken: 1 sec\n",
            "End of epoch 199 / 1000 \t Time Taken: 1 sec\n",
            "(epoch: 200, iters: 6, time: 0.799) G_GAN_image: 1.471 G_GAN_person: 0.540 G_L1: 6.440 D_image_real: 0.160 D_image_fake: 0.368 D_person_real: 0.152 D_person_fake: 0.073 \n",
            "saving the model at the end of epoch 200, iters 1200\n",
            "End of epoch 200 / 1000 \t Time Taken: 4 sec\n",
            "End of epoch 201 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000200 -> 0.000200\n",
            "End of epoch 202 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000200 -> 0.000199\n",
            "End of epoch 203 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000199 -> 0.000199\n",
            "End of epoch 204 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000199 -> 0.000199\n",
            "End of epoch 205 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000199 -> 0.000199\n",
            "End of epoch 206 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000199 -> 0.000198\n",
            "End of epoch 207 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000198 -> 0.000198\n",
            "End of epoch 208 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000198 -> 0.000198\n",
            "End of epoch 209 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000198 -> 0.000198\n",
            "End of epoch 210 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000198 -> 0.000197\n",
            "End of epoch 211 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000197 -> 0.000197\n",
            "End of epoch 212 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000197 -> 0.000197\n",
            "End of epoch 213 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000197 -> 0.000197\n",
            "End of epoch 214 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000197 -> 0.000196\n",
            "End of epoch 215 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000196 -> 0.000196\n",
            "End of epoch 216 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000196 -> 0.000196\n",
            "(epoch: 217, iters: 4, time: 0.811) G_GAN_image: 0.500 G_GAN_person: 0.398 G_L1: 5.442 D_image_real: 1.096 D_image_fake: 0.589 D_person_real: 0.297 D_person_fake: 0.013 \n",
            "End of epoch 217 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000196 -> 0.000196\n",
            "End of epoch 218 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000196 -> 0.000195\n",
            "End of epoch 219 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000195 -> 0.000195\n",
            "End of epoch 220 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000195 -> 0.000195\n",
            "End of epoch 221 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000195 -> 0.000195\n",
            "End of epoch 222 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000195 -> 0.000194\n",
            "End of epoch 223 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000194 -> 0.000194\n",
            "End of epoch 224 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000194 -> 0.000194\n",
            "End of epoch 225 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000194 -> 0.000194\n",
            "End of epoch 226 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000194 -> 0.000193\n",
            "End of epoch 227 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000193 -> 0.000193\n",
            "End of epoch 228 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000193 -> 0.000193\n",
            "End of epoch 229 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000193 -> 0.000193\n",
            "End of epoch 230 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000193 -> 0.000192\n",
            "End of epoch 231 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000192 -> 0.000192\n",
            "End of epoch 232 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000192 -> 0.000192\n",
            "End of epoch 233 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000192 -> 0.000192\n",
            "(epoch: 234, iters: 2, time: 0.704) G_GAN_image: 2.525 G_GAN_person: 0.698 G_L1: 5.998 D_image_real: 0.261 D_image_fake: 0.443 D_person_real: 0.172 D_person_fake: 0.161 \n",
            "End of epoch 234 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000192 -> 0.000191\n",
            "End of epoch 235 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000191 -> 0.000191\n",
            "End of epoch 236 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000191 -> 0.000191\n",
            "End of epoch 237 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000191 -> 0.000191\n",
            "End of epoch 238 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000191 -> 0.000190\n",
            "End of epoch 239 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000190 -> 0.000190\n",
            "End of epoch 240 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000190 -> 0.000190\n",
            "End of epoch 241 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000190 -> 0.000190\n",
            "End of epoch 242 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000190 -> 0.000189\n",
            "End of epoch 243 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000189 -> 0.000189\n",
            "End of epoch 244 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000189 -> 0.000189\n",
            "End of epoch 245 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000189 -> 0.000189\n",
            "End of epoch 246 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000189 -> 0.000188\n",
            "End of epoch 247 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000188 -> 0.000188\n",
            "End of epoch 248 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000188 -> 0.000188\n",
            "End of epoch 249 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000188 -> 0.000188\n",
            "(epoch: 250, iters: 6, time: 1.321) G_GAN_image: 1.579 G_GAN_person: 1.247 G_L1: 3.985 D_image_real: 0.226 D_image_fake: 0.531 D_person_real: 0.089 D_person_fake: 0.039 \n",
            "End of epoch 250 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000188 -> 0.000187\n",
            "End of epoch 251 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000187 -> 0.000187\n",
            "End of epoch 252 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000187 -> 0.000187\n",
            "End of epoch 253 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000187 -> 0.000187\n",
            "End of epoch 254 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000187 -> 0.000186\n",
            "End of epoch 255 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000186 -> 0.000186\n",
            "End of epoch 256 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000186 -> 0.000186\n",
            "End of epoch 257 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000186 -> 0.000186\n",
            "End of epoch 258 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000186 -> 0.000185\n",
            "End of epoch 259 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000185 -> 0.000185\n",
            "End of epoch 260 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000185 -> 0.000185\n",
            "End of epoch 261 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000185 -> 0.000185\n",
            "End of epoch 262 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000185 -> 0.000184\n",
            "End of epoch 263 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000184 -> 0.000184\n",
            "End of epoch 264 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000184 -> 0.000184\n",
            "End of epoch 265 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000184 -> 0.000184\n",
            "End of epoch 266 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000184 -> 0.000183\n",
            "(epoch: 267, iters: 4, time: 1.145) G_GAN_image: 1.395 G_GAN_person: 0.880 G_L1: 3.573 D_image_real: 0.129 D_image_fake: 1.300 D_person_real: 0.189 D_person_fake: 0.023 \n",
            "saving the latest model (epoch 267, total_steps 1600)\n",
            "End of epoch 267 / 1000 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000183 -> 0.000183\n",
            "End of epoch 268 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000183 -> 0.000183\n",
            "End of epoch 269 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000183 -> 0.000183\n",
            "End of epoch 270 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000183 -> 0.000182\n",
            "End of epoch 271 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000182 -> 0.000182\n",
            "End of epoch 272 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000182 -> 0.000182\n",
            "End of epoch 273 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000182 -> 0.000182\n",
            "End of epoch 274 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000182 -> 0.000181\n",
            "End of epoch 275 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000181 -> 0.000181\n",
            "End of epoch 276 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000181 -> 0.000181\n",
            "End of epoch 277 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000181 -> 0.000181\n",
            "End of epoch 278 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000181 -> 0.000180\n",
            "End of epoch 279 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000180 -> 0.000180\n",
            "End of epoch 280 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000180 -> 0.000180\n",
            "End of epoch 281 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000180 -> 0.000180\n",
            "End of epoch 282 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000180 -> 0.000179\n",
            "End of epoch 283 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000179 -> 0.000179\n",
            "(epoch: 284, iters: 2, time: 0.761) G_GAN_image: 0.314 G_GAN_person: 0.794 G_L1: 4.683 D_image_real: 0.221 D_image_fake: 0.138 D_person_real: 0.051 D_person_fake: 0.067 \n",
            "End of epoch 284 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000179 -> 0.000179\n",
            "End of epoch 285 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000179 -> 0.000179\n",
            "End of epoch 286 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000179 -> 0.000178\n",
            "End of epoch 287 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000178 -> 0.000178\n",
            "End of epoch 288 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000178 -> 0.000178\n",
            "End of epoch 289 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000178 -> 0.000178\n",
            "End of epoch 290 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000178 -> 0.000177\n",
            "End of epoch 291 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000177 -> 0.000177\n",
            "End of epoch 292 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000177 -> 0.000177\n",
            "End of epoch 293 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000177 -> 0.000177\n",
            "End of epoch 294 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000177 -> 0.000176\n",
            "End of epoch 295 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000176 -> 0.000176\n",
            "End of epoch 296 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000176 -> 0.000176\n",
            "End of epoch 297 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000176 -> 0.000176\n",
            "End of epoch 298 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000176 -> 0.000175\n",
            "End of epoch 299 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000175 -> 0.000175\n",
            "(epoch: 300, iters: 6, time: 0.948) G_GAN_image: 1.376 G_GAN_person: 0.807 G_L1: 5.442 D_image_real: 0.529 D_image_fake: 0.237 D_person_real: 0.035 D_person_fake: 0.043 \n",
            "End of epoch 300 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000175 -> 0.000175\n",
            "End of epoch 301 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000175 -> 0.000175\n",
            "End of epoch 302 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000175 -> 0.000174\n",
            "End of epoch 303 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000174 -> 0.000174\n",
            "End of epoch 304 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000174 -> 0.000174\n",
            "End of epoch 305 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000174 -> 0.000174\n",
            "End of epoch 306 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000174 -> 0.000173\n",
            "End of epoch 307 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000173 -> 0.000173\n",
            "End of epoch 308 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000173 -> 0.000173\n",
            "End of epoch 309 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000173 -> 0.000173\n",
            "End of epoch 310 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000173 -> 0.000172\n",
            "End of epoch 311 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000172 -> 0.000172\n",
            "End of epoch 312 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000172 -> 0.000172\n",
            "End of epoch 313 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000172 -> 0.000172\n",
            "End of epoch 314 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000172 -> 0.000171\n",
            "End of epoch 315 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000171 -> 0.000171\n",
            "End of epoch 316 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000171 -> 0.000171\n",
            "(epoch: 317, iters: 4, time: 0.747) G_GAN_image: 2.004 G_GAN_person: 0.563 G_L1: 5.323 D_image_real: 0.200 D_image_fake: 0.475 D_person_real: 0.134 D_person_fake: 0.366 \n",
            "End of epoch 317 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000171 -> 0.000171\n",
            "End of epoch 318 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000171 -> 0.000170\n",
            "End of epoch 319 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000170 -> 0.000170\n",
            "End of epoch 320 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000170 -> 0.000170\n",
            "End of epoch 321 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000170 -> 0.000170\n",
            "End of epoch 322 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000170 -> 0.000169\n",
            "End of epoch 323 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000169 -> 0.000169\n",
            "End of epoch 324 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000169 -> 0.000169\n",
            "End of epoch 325 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000169 -> 0.000169\n",
            "End of epoch 326 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000169 -> 0.000168\n",
            "End of epoch 327 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000168 -> 0.000168\n",
            "End of epoch 328 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000168 -> 0.000168\n",
            "End of epoch 329 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000168 -> 0.000168\n",
            "End of epoch 330 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000168 -> 0.000167\n",
            "End of epoch 331 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000167 -> 0.000167\n",
            "End of epoch 332 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000167 -> 0.000167\n",
            "End of epoch 333 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000167 -> 0.000167\n",
            "(epoch: 334, iters: 2, time: 1.166) G_GAN_image: 1.274 G_GAN_person: 0.787 G_L1: 3.123 D_image_real: 0.916 D_image_fake: 0.213 D_person_real: 0.100 D_person_fake: 0.120 \n",
            "End of epoch 334 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000167 -> 0.000166\n",
            "End of epoch 335 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000166 -> 0.000166\n",
            "End of epoch 336 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000166 -> 0.000166\n",
            "End of epoch 337 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000166 -> 0.000166\n",
            "End of epoch 338 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000166 -> 0.000165\n",
            "End of epoch 339 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000165 -> 0.000165\n",
            "End of epoch 340 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000165 -> 0.000165\n",
            "End of epoch 341 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000165 -> 0.000165\n",
            "End of epoch 342 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000165 -> 0.000164\n",
            "End of epoch 343 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000164 -> 0.000164\n",
            "End of epoch 344 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000164 -> 0.000164\n",
            "End of epoch 345 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000164 -> 0.000164\n",
            "End of epoch 346 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000164 -> 0.000163\n",
            "End of epoch 347 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000163 -> 0.000163\n",
            "End of epoch 348 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000163 -> 0.000163\n",
            "End of epoch 349 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000163 -> 0.000163\n",
            "(epoch: 350, iters: 6, time: 1.109) G_GAN_image: 2.371 G_GAN_person: 0.686 G_L1: 4.885 D_image_real: 0.275 D_image_fake: 0.406 D_person_real: 0.102 D_person_fake: 0.050 \n",
            "End of epoch 350 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000163 -> 0.000162\n",
            "End of epoch 351 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000162 -> 0.000162\n",
            "End of epoch 352 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000162 -> 0.000162\n",
            "End of epoch 353 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000162 -> 0.000162\n",
            "End of epoch 354 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000162 -> 0.000161\n",
            "End of epoch 355 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000161 -> 0.000161\n",
            "End of epoch 356 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000161 -> 0.000161\n",
            "End of epoch 357 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000161 -> 0.000161\n",
            "End of epoch 358 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000161 -> 0.000160\n",
            "End of epoch 359 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000160 -> 0.000160\n",
            "End of epoch 360 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000160 -> 0.000160\n",
            "End of epoch 361 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000160 -> 0.000160\n",
            "End of epoch 362 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000160 -> 0.000159\n",
            "End of epoch 363 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000159 -> 0.000159\n",
            "End of epoch 364 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000159 -> 0.000159\n",
            "End of epoch 365 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000159 -> 0.000159\n",
            "End of epoch 366 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000159 -> 0.000158\n",
            "(epoch: 367, iters: 4, time: 1.173) G_GAN_image: 2.818 G_GAN_person: 1.151 G_L1: 2.967 D_image_real: 0.377 D_image_fake: 0.073 D_person_real: 0.139 D_person_fake: 0.268 \n",
            "End of epoch 367 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000158 -> 0.000158\n",
            "End of epoch 368 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000158 -> 0.000158\n",
            "End of epoch 369 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000158 -> 0.000158\n",
            "End of epoch 370 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000158 -> 0.000157\n",
            "End of epoch 371 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000157 -> 0.000157\n",
            "End of epoch 372 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000157 -> 0.000157\n",
            "End of epoch 373 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000157 -> 0.000157\n",
            "End of epoch 374 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000157 -> 0.000156\n",
            "End of epoch 375 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000156 -> 0.000156\n",
            "End of epoch 376 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000156 -> 0.000156\n",
            "End of epoch 377 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000156 -> 0.000156\n",
            "End of epoch 378 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000156 -> 0.000155\n",
            "End of epoch 379 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000155 -> 0.000155\n",
            "End of epoch 380 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000155 -> 0.000155\n",
            "End of epoch 381 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000155 -> 0.000155\n",
            "End of epoch 382 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000155 -> 0.000154\n",
            "End of epoch 383 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000154 -> 0.000154\n",
            "(epoch: 384, iters: 2, time: 0.819) G_GAN_image: 3.230 G_GAN_person: 0.844 G_L1: 4.459 D_image_real: 0.375 D_image_fake: 0.077 D_person_real: 0.204 D_person_fake: 0.023 \n",
            "End of epoch 384 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000154 -> 0.000154\n",
            "End of epoch 385 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000154 -> 0.000154\n",
            "End of epoch 386 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000154 -> 0.000153\n",
            "End of epoch 387 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000153 -> 0.000153\n",
            "End of epoch 388 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000153 -> 0.000153\n",
            "End of epoch 389 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000153 -> 0.000153\n",
            "End of epoch 390 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000153 -> 0.000152\n",
            "End of epoch 391 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000152 -> 0.000152\n",
            "End of epoch 392 / 1000 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000152 -> 0.000152\n",
            "End of epoch 393 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000152 -> 0.000152\n",
            "End of epoch 394 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000152 -> 0.000151\n",
            "End of epoch 395 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000151 -> 0.000151\n",
            "End of epoch 396 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000151 -> 0.000151\n",
            "End of epoch 397 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000151 -> 0.000151\n",
            "End of epoch 398 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000151 -> 0.000150\n",
            "End of epoch 399 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000150 -> 0.000150\n",
            "(epoch: 400, iters: 6, time: 1.541) G_GAN_image: 2.018 G_GAN_person: 0.954 G_L1: 2.931 D_image_real: 0.123 D_image_fake: 0.078 D_person_real: 0.085 D_person_fake: 0.012 \n",
            "saving the latest model (epoch 400, total_steps 2400)\n",
            "saving the model at the end of epoch 400, iters 2400\n",
            "End of epoch 400 / 1000 \t Time Taken: 6 sec\n",
            "update learning rate: 0.000150 -> 0.000150\n",
            "End of epoch 401 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000150 -> 0.000150\n",
            "End of epoch 402 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000150 -> 0.000149\n",
            "End of epoch 403 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000149 -> 0.000149\n",
            "End of epoch 404 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000149 -> 0.000149\n",
            "End of epoch 405 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000149 -> 0.000149\n",
            "End of epoch 406 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000149 -> 0.000148\n",
            "End of epoch 407 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000148 -> 0.000148\n",
            "End of epoch 408 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000148 -> 0.000148\n",
            "End of epoch 409 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000148 -> 0.000148\n",
            "End of epoch 410 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000148 -> 0.000147\n",
            "End of epoch 411 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000147 -> 0.000147\n",
            "End of epoch 412 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000147 -> 0.000147\n",
            "End of epoch 413 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000147 -> 0.000147\n",
            "End of epoch 414 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000147 -> 0.000146\n",
            "End of epoch 415 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000146 -> 0.000146\n",
            "End of epoch 416 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000146 -> 0.000146\n",
            "(epoch: 417, iters: 4, time: 0.998) G_GAN_image: 1.352 G_GAN_person: 0.878 G_L1: 2.836 D_image_real: 0.097 D_image_fake: 0.545 D_person_real: 0.245 D_person_fake: 0.112 \n",
            "End of epoch 417 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000146 -> 0.000146\n",
            "End of epoch 418 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000146 -> 0.000145\n",
            "End of epoch 419 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000145 -> 0.000145\n",
            "End of epoch 420 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000145 -> 0.000145\n",
            "End of epoch 421 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000145 -> 0.000145\n",
            "End of epoch 422 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000145 -> 0.000144\n",
            "End of epoch 423 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000144 -> 0.000144\n",
            "End of epoch 424 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000144 -> 0.000144\n",
            "End of epoch 425 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000144 -> 0.000144\n",
            "End of epoch 426 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000144 -> 0.000143\n",
            "End of epoch 427 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000143 -> 0.000143\n",
            "End of epoch 428 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000143 -> 0.000143\n",
            "End of epoch 429 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000143 -> 0.000143\n",
            "End of epoch 430 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000143 -> 0.000142\n",
            "End of epoch 431 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000142 -> 0.000142\n",
            "End of epoch 432 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000142 -> 0.000142\n",
            "End of epoch 433 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000142 -> 0.000142\n",
            "(epoch: 434, iters: 2, time: 0.929) G_GAN_image: 0.663 G_GAN_person: 0.615 G_L1: 4.300 D_image_real: 0.510 D_image_fake: 0.335 D_person_real: 0.060 D_person_fake: 0.149 \n",
            "End of epoch 434 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000142 -> 0.000141\n",
            "End of epoch 435 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000141 -> 0.000141\n",
            "End of epoch 436 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000141 -> 0.000141\n",
            "End of epoch 437 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000141 -> 0.000141\n",
            "End of epoch 438 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000141 -> 0.000140\n",
            "End of epoch 439 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000140 -> 0.000140\n",
            "End of epoch 440 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000140 -> 0.000140\n",
            "End of epoch 441 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000140 -> 0.000140\n",
            "End of epoch 442 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000140 -> 0.000139\n",
            "End of epoch 443 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000139 -> 0.000139\n",
            "End of epoch 444 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000139 -> 0.000139\n",
            "End of epoch 445 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000139 -> 0.000139\n",
            "End of epoch 446 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000139 -> 0.000138\n",
            "End of epoch 447 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000138 -> 0.000138\n",
            "End of epoch 448 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000138 -> 0.000138\n",
            "End of epoch 449 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000138 -> 0.000138\n",
            "(epoch: 450, iters: 6, time: 1.311) G_GAN_image: 4.032 G_GAN_person: 0.713 G_L1: 5.036 D_image_real: 0.099 D_image_fake: 0.056 D_person_real: 0.097 D_person_fake: 0.067 \n",
            "End of epoch 450 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000138 -> 0.000137\n",
            "End of epoch 451 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000137 -> 0.000137\n",
            "End of epoch 452 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000137 -> 0.000137\n",
            "End of epoch 453 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000137 -> 0.000137\n",
            "End of epoch 454 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000137 -> 0.000136\n",
            "End of epoch 455 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000136 -> 0.000136\n",
            "End of epoch 456 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000136 -> 0.000136\n",
            "End of epoch 457 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000136 -> 0.000136\n",
            "End of epoch 458 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000136 -> 0.000135\n",
            "End of epoch 459 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000135 -> 0.000135\n",
            "End of epoch 460 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000135 -> 0.000135\n",
            "End of epoch 461 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000135 -> 0.000135\n",
            "End of epoch 462 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000135 -> 0.000134\n",
            "End of epoch 463 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000134 -> 0.000134\n",
            "End of epoch 464 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000134 -> 0.000134\n",
            "End of epoch 465 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000134 -> 0.000134\n",
            "End of epoch 466 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000134 -> 0.000133\n",
            "(epoch: 467, iters: 4, time: 0.850) G_GAN_image: 0.812 G_GAN_person: 0.508 G_L1: 4.285 D_image_real: 0.689 D_image_fake: 0.690 D_person_real: 0.363 D_person_fake: 0.143 \n",
            "End of epoch 467 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000133 -> 0.000133\n",
            "End of epoch 468 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000133 -> 0.000133\n",
            "End of epoch 469 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000133 -> 0.000133\n",
            "End of epoch 470 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000133 -> 0.000132\n",
            "End of epoch 471 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000132 -> 0.000132\n",
            "End of epoch 472 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000132 -> 0.000132\n",
            "End of epoch 473 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000132 -> 0.000132\n",
            "End of epoch 474 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000132 -> 0.000131\n",
            "End of epoch 475 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000131 -> 0.000131\n",
            "End of epoch 476 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000131 -> 0.000131\n",
            "End of epoch 477 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000131 -> 0.000131\n",
            "End of epoch 478 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000131 -> 0.000130\n",
            "End of epoch 479 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000130 -> 0.000130\n",
            "End of epoch 480 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000130 -> 0.000130\n",
            "End of epoch 481 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000130 -> 0.000130\n",
            "End of epoch 482 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000130 -> 0.000129\n",
            "End of epoch 483 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000129 -> 0.000129\n",
            "(epoch: 484, iters: 2, time: 0.851) G_GAN_image: 0.619 G_GAN_person: 0.763 G_L1: 3.630 D_image_real: 0.679 D_image_fake: 0.763 D_person_real: 0.021 D_person_fake: 0.085 \n",
            "End of epoch 484 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000129 -> 0.000129\n",
            "End of epoch 485 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000129 -> 0.000129\n",
            "End of epoch 486 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000129 -> 0.000128\n",
            "End of epoch 487 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000128 -> 0.000128\n",
            "End of epoch 488 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000128 -> 0.000128\n",
            "End of epoch 489 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000128 -> 0.000128\n",
            "End of epoch 490 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000128 -> 0.000127\n",
            "End of epoch 491 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000127 -> 0.000127\n",
            "End of epoch 492 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000127 -> 0.000127\n",
            "End of epoch 493 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000127 -> 0.000127\n",
            "End of epoch 494 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000127 -> 0.000126\n",
            "End of epoch 495 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000126 -> 0.000126\n",
            "End of epoch 496 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000126 -> 0.000126\n",
            "End of epoch 497 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000126 -> 0.000126\n",
            "End of epoch 498 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000126 -> 0.000125\n",
            "End of epoch 499 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000125 -> 0.000125\n",
            "(epoch: 500, iters: 6, time: 1.314) G_GAN_image: 0.617 G_GAN_person: 0.759 G_L1: 3.853 D_image_real: 0.788 D_image_fake: 0.489 D_person_real: 0.147 D_person_fake: 0.036 \n",
            "End of epoch 500 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000125 -> 0.000125\n",
            "End of epoch 501 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000125 -> 0.000125\n",
            "End of epoch 502 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000125 -> 0.000124\n",
            "End of epoch 503 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000124 -> 0.000124\n",
            "End of epoch 504 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000124 -> 0.000124\n",
            "End of epoch 505 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000124 -> 0.000124\n",
            "End of epoch 506 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000124 -> 0.000123\n",
            "End of epoch 507 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000123 -> 0.000123\n",
            "End of epoch 508 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000123 -> 0.000123\n",
            "End of epoch 509 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000123 -> 0.000123\n",
            "End of epoch 510 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000123 -> 0.000122\n",
            "End of epoch 511 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000122 -> 0.000122\n",
            "End of epoch 512 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000122 -> 0.000122\n",
            "End of epoch 513 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000122 -> 0.000122\n",
            "End of epoch 514 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000122 -> 0.000121\n",
            "End of epoch 515 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000121 -> 0.000121\n",
            "End of epoch 516 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000121 -> 0.000121\n",
            "(epoch: 517, iters: 4, time: 1.209) G_GAN_image: 1.002 G_GAN_person: 0.496 G_L1: 4.131 D_image_real: 0.777 D_image_fake: 0.376 D_person_real: 0.222 D_person_fake: 0.013 \n",
            "End of epoch 517 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000121 -> 0.000121\n",
            "End of epoch 518 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000121 -> 0.000120\n",
            "End of epoch 519 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000120 -> 0.000120\n",
            "End of epoch 520 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000120 -> 0.000120\n",
            "End of epoch 521 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000120 -> 0.000120\n",
            "End of epoch 522 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000120 -> 0.000119\n",
            "End of epoch 523 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000119 -> 0.000119\n",
            "End of epoch 524 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000119 -> 0.000119\n",
            "End of epoch 525 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000119 -> 0.000119\n",
            "End of epoch 526 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000119 -> 0.000118\n",
            "End of epoch 527 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000118 -> 0.000118\n",
            "End of epoch 528 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000118 -> 0.000118\n",
            "End of epoch 529 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000118 -> 0.000118\n",
            "End of epoch 530 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000118 -> 0.000117\n",
            "End of epoch 531 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000117 -> 0.000117\n",
            "End of epoch 532 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000117 -> 0.000117\n",
            "End of epoch 533 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000117 -> 0.000117\n",
            "(epoch: 534, iters: 2, time: 1.029) G_GAN_image: 0.821 G_GAN_person: 1.035 G_L1: 3.872 D_image_real: 0.605 D_image_fake: 0.659 D_person_real: 0.045 D_person_fake: 0.013 \n",
            "saving the latest model (epoch 534, total_steps 3200)\n",
            "End of epoch 534 / 1000 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000117 -> 0.000116\n",
            "End of epoch 535 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000116 -> 0.000116\n",
            "End of epoch 536 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000116 -> 0.000116\n",
            "End of epoch 537 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000116 -> 0.000116\n",
            "End of epoch 538 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000116 -> 0.000115\n",
            "End of epoch 539 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000115 -> 0.000115\n",
            "End of epoch 540 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000115 -> 0.000115\n",
            "End of epoch 541 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000115 -> 0.000115\n",
            "End of epoch 542 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000115 -> 0.000114\n",
            "End of epoch 543 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000114 -> 0.000114\n",
            "End of epoch 544 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000114 -> 0.000114\n",
            "End of epoch 545 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000114 -> 0.000114\n",
            "End of epoch 546 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000114 -> 0.000113\n",
            "End of epoch 547 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000113 -> 0.000113\n",
            "End of epoch 548 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000113 -> 0.000113\n",
            "End of epoch 549 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000113 -> 0.000113\n",
            "(epoch: 550, iters: 6, time: 1.308) G_GAN_image: 0.675 G_GAN_person: 0.788 G_L1: 3.807 D_image_real: 0.734 D_image_fake: 0.661 D_person_real: 0.111 D_person_fake: 0.049 \n",
            "End of epoch 550 / 1000 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000113 -> 0.000112\n",
            "End of epoch 551 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000112 -> 0.000112\n",
            "End of epoch 552 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000112 -> 0.000112\n",
            "End of epoch 553 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000112 -> 0.000112\n",
            "End of epoch 554 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000112 -> 0.000111\n",
            "End of epoch 555 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000111 -> 0.000111\n",
            "End of epoch 556 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000111 -> 0.000111\n",
            "End of epoch 557 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000111 -> 0.000111\n",
            "End of epoch 558 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000111 -> 0.000110\n",
            "End of epoch 559 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000110 -> 0.000110\n",
            "End of epoch 560 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000110 -> 0.000110\n",
            "End of epoch 561 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000110 -> 0.000110\n",
            "End of epoch 562 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000110 -> 0.000109\n",
            "End of epoch 563 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000109 -> 0.000109\n",
            "End of epoch 564 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000109 -> 0.000109\n",
            "End of epoch 565 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000109 -> 0.000109\n",
            "End of epoch 566 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000109 -> 0.000108\n",
            "(epoch: 567, iters: 4, time: 1.090) G_GAN_image: 0.551 G_GAN_person: 0.740 G_L1: 4.193 D_image_real: 0.488 D_image_fake: 0.685 D_person_real: 0.114 D_person_fake: 0.101 \n",
            "End of epoch 567 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000108 -> 0.000108\n",
            "End of epoch 568 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000108 -> 0.000108\n",
            "End of epoch 569 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000108 -> 0.000108\n",
            "End of epoch 570 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000108 -> 0.000107\n",
            "End of epoch 571 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000107 -> 0.000107\n",
            "End of epoch 572 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000107 -> 0.000107\n",
            "End of epoch 573 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000107 -> 0.000107\n",
            "End of epoch 574 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000107 -> 0.000106\n",
            "End of epoch 575 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000106 -> 0.000106\n",
            "End of epoch 576 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000106 -> 0.000106\n",
            "End of epoch 577 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000106 -> 0.000106\n",
            "End of epoch 578 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000106 -> 0.000105\n",
            "End of epoch 579 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000105 -> 0.000105\n",
            "End of epoch 580 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000105 -> 0.000105\n",
            "End of epoch 581 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000105 -> 0.000105\n",
            "End of epoch 582 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000105 -> 0.000104\n",
            "End of epoch 583 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000104 -> 0.000104\n",
            "(epoch: 584, iters: 2, time: 1.263) G_GAN_image: 0.812 G_GAN_person: 0.490 G_L1: 3.673 D_image_real: 0.797 D_image_fake: 0.604 D_person_real: 0.084 D_person_fake: 0.122 \n",
            "End of epoch 584 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000104 -> 0.000104\n",
            "End of epoch 585 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000104 -> 0.000104\n",
            "End of epoch 586 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000104 -> 0.000103\n",
            "End of epoch 587 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000103 -> 0.000103\n",
            "End of epoch 588 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000103 -> 0.000103\n",
            "End of epoch 589 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000103 -> 0.000103\n",
            "End of epoch 590 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000103 -> 0.000102\n",
            "End of epoch 591 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000102 -> 0.000102\n",
            "End of epoch 592 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000102 -> 0.000102\n",
            "End of epoch 593 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000102 -> 0.000102\n",
            "End of epoch 594 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000102 -> 0.000101\n",
            "End of epoch 595 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000101 -> 0.000101\n",
            "End of epoch 596 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000101 -> 0.000101\n",
            "End of epoch 597 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000101 -> 0.000101\n",
            "End of epoch 598 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000101 -> 0.000100\n",
            "End of epoch 599 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000100 -> 0.000100\n",
            "(epoch: 600, iters: 6, time: 1.148) G_GAN_image: 0.912 G_GAN_person: 0.758 G_L1: 4.348 D_image_real: 0.362 D_image_fake: 0.909 D_person_real: 0.187 D_person_fake: 0.038 \n",
            "saving the model at the end of epoch 600, iters 3600\n",
            "End of epoch 600 / 1000 \t Time Taken: 4 sec\n",
            "update learning rate: 0.000100 -> 0.000100\n",
            "End of epoch 601 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000100 -> 0.000100\n",
            "End of epoch 602 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000100 -> 0.000099\n",
            "End of epoch 603 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000099 -> 0.000099\n",
            "End of epoch 604 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000099 -> 0.000099\n",
            "End of epoch 605 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000099 -> 0.000099\n",
            "End of epoch 606 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000099 -> 0.000098\n",
            "End of epoch 607 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000098 -> 0.000098\n",
            "End of epoch 608 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000098 -> 0.000098\n",
            "End of epoch 609 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000098 -> 0.000098\n",
            "End of epoch 610 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000098 -> 0.000097\n",
            "End of epoch 611 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000097 -> 0.000097\n",
            "End of epoch 612 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000097 -> 0.000097\n",
            "End of epoch 613 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000097 -> 0.000097\n",
            "End of epoch 614 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000097 -> 0.000096\n",
            "End of epoch 615 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000096 -> 0.000096\n",
            "End of epoch 616 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000096 -> 0.000096\n",
            "(epoch: 617, iters: 4, time: 1.100) G_GAN_image: 0.922 G_GAN_person: 0.817 G_L1: 4.523 D_image_real: 0.510 D_image_fake: 0.325 D_person_real: 0.061 D_person_fake: 0.042 \n",
            "End of epoch 617 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000096 -> 0.000096\n",
            "End of epoch 618 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000096 -> 0.000095\n",
            "End of epoch 619 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000095 -> 0.000095\n",
            "End of epoch 620 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000095 -> 0.000095\n",
            "End of epoch 621 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000095 -> 0.000095\n",
            "End of epoch 622 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000095 -> 0.000094\n",
            "End of epoch 623 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000094 -> 0.000094\n",
            "End of epoch 624 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000094 -> 0.000094\n",
            "End of epoch 625 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000094 -> 0.000094\n",
            "End of epoch 626 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000094 -> 0.000093\n",
            "End of epoch 627 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000093 -> 0.000093\n",
            "End of epoch 628 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000093 -> 0.000093\n",
            "End of epoch 629 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000093 -> 0.000093\n",
            "End of epoch 630 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000093 -> 0.000092\n",
            "End of epoch 631 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000092 -> 0.000092\n",
            "End of epoch 632 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000092 -> 0.000092\n",
            "End of epoch 633 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000092 -> 0.000092\n",
            "(epoch: 634, iters: 2, time: 1.208) G_GAN_image: 1.508 G_GAN_person: 0.724 G_L1: 5.109 D_image_real: 0.910 D_image_fake: 0.307 D_person_real: 0.141 D_person_fake: 0.079 \n",
            "End of epoch 634 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000092 -> 0.000091\n",
            "End of epoch 635 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000091 -> 0.000091\n",
            "End of epoch 636 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000091 -> 0.000091\n",
            "End of epoch 637 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000091 -> 0.000091\n",
            "End of epoch 638 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000091 -> 0.000090\n",
            "End of epoch 639 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000090 -> 0.000090\n",
            "End of epoch 640 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000090 -> 0.000090\n",
            "End of epoch 641 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000090 -> 0.000090\n",
            "End of epoch 642 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000090 -> 0.000089\n",
            "End of epoch 643 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000089 -> 0.000089\n",
            "End of epoch 644 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000089 -> 0.000089\n",
            "End of epoch 645 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000089 -> 0.000089\n",
            "End of epoch 646 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000089 -> 0.000088\n",
            "End of epoch 647 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000088 -> 0.000088\n",
            "End of epoch 648 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000088 -> 0.000088\n",
            "End of epoch 649 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000088 -> 0.000088\n",
            "(epoch: 650, iters: 6, time: 1.323) G_GAN_image: 1.321 G_GAN_person: 0.865 G_L1: 4.927 D_image_real: 0.283 D_image_fake: 0.335 D_person_real: 0.032 D_person_fake: 0.048 \n",
            "End of epoch 650 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000088 -> 0.000087\n",
            "End of epoch 651 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000087 -> 0.000087\n",
            "End of epoch 652 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000087 -> 0.000087\n",
            "End of epoch 653 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000087 -> 0.000087\n",
            "End of epoch 654 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000087 -> 0.000086\n",
            "End of epoch 655 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000086 -> 0.000086\n",
            "End of epoch 656 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000086 -> 0.000086\n",
            "End of epoch 657 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000086 -> 0.000086\n",
            "End of epoch 658 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000086 -> 0.000085\n",
            "End of epoch 659 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000085 -> 0.000085\n",
            "End of epoch 660 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000085 -> 0.000085\n",
            "End of epoch 661 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000085 -> 0.000085\n",
            "End of epoch 662 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000085 -> 0.000084\n",
            "End of epoch 663 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000084 -> 0.000084\n",
            "End of epoch 664 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000084 -> 0.000084\n",
            "End of epoch 665 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000084 -> 0.000084\n",
            "End of epoch 666 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000084 -> 0.000083\n",
            "(epoch: 667, iters: 4, time: 1.465) G_GAN_image: 1.607 G_GAN_person: 0.704 G_L1: 2.574 D_image_real: 0.028 D_image_fake: 0.097 D_person_real: 0.086 D_person_fake: 0.022 \n",
            "saving the latest model (epoch 667, total_steps 4000)\n",
            "End of epoch 667 / 1000 \t Time Taken: 4 sec\n",
            "update learning rate: 0.000083 -> 0.000083\n",
            "End of epoch 668 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000083 -> 0.000083\n",
            "End of epoch 669 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000083 -> 0.000083\n",
            "End of epoch 670 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000083 -> 0.000082\n",
            "End of epoch 671 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000082 -> 0.000082\n",
            "End of epoch 672 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000082 -> 0.000082\n",
            "End of epoch 673 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000082 -> 0.000082\n",
            "End of epoch 674 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000082 -> 0.000081\n",
            "End of epoch 675 / 1000 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000081 -> 0.000081\n",
            "End of epoch 676 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000081 -> 0.000081\n",
            "End of epoch 677 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000081 -> 0.000081\n",
            "End of epoch 678 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000081 -> 0.000080\n",
            "End of epoch 679 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000080 -> 0.000080\n",
            "End of epoch 680 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000080 -> 0.000080\n",
            "End of epoch 681 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000080 -> 0.000080\n",
            "End of epoch 682 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000080 -> 0.000079\n",
            "End of epoch 683 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000079 -> 0.000079\n",
            "(epoch: 684, iters: 2, time: 1.037) G_GAN_image: 2.177 G_GAN_person: 0.761 G_L1: 4.450 D_image_real: 0.110 D_image_fake: 0.184 D_person_real: 0.037 D_person_fake: 0.089 \n",
            "End of epoch 684 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000079 -> 0.000079\n",
            "End of epoch 685 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000079 -> 0.000079\n",
            "End of epoch 686 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000079 -> 0.000078\n",
            "End of epoch 687 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000078 -> 0.000078\n",
            "End of epoch 688 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000078 -> 0.000078\n",
            "End of epoch 689 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000078 -> 0.000078\n",
            "End of epoch 690 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000078 -> 0.000077\n",
            "End of epoch 691 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000077 -> 0.000077\n",
            "End of epoch 692 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000077 -> 0.000077\n",
            "End of epoch 693 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000077 -> 0.000077\n",
            "End of epoch 694 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000077 -> 0.000076\n",
            "End of epoch 695 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000076 -> 0.000076\n",
            "End of epoch 696 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000076 -> 0.000076\n",
            "End of epoch 697 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000076 -> 0.000076\n",
            "End of epoch 698 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000076 -> 0.000075\n",
            "End of epoch 699 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000075 -> 0.000075\n",
            "(epoch: 700, iters: 6, time: 1.597) G_GAN_image: 1.255 G_GAN_person: 0.888 G_L1: 3.619 D_image_real: 0.148 D_image_fake: 0.064 D_person_real: 0.027 D_person_fake: 0.023 \n",
            "End of epoch 700 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000075 -> 0.000075\n",
            "End of epoch 701 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000075 -> 0.000075\n",
            "End of epoch 702 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000075 -> 0.000074\n",
            "End of epoch 703 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000074 -> 0.000074\n",
            "End of epoch 704 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000074 -> 0.000074\n",
            "End of epoch 705 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000074 -> 0.000074\n",
            "End of epoch 706 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000074 -> 0.000073\n",
            "End of epoch 707 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000073 -> 0.000073\n",
            "End of epoch 708 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000073 -> 0.000073\n",
            "End of epoch 709 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000073 -> 0.000073\n",
            "End of epoch 710 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000073 -> 0.000072\n",
            "End of epoch 711 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000072 -> 0.000072\n",
            "End of epoch 712 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000072 -> 0.000072\n",
            "End of epoch 713 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000072 -> 0.000072\n",
            "End of epoch 714 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000072 -> 0.000071\n",
            "End of epoch 715 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000071 -> 0.000071\n",
            "End of epoch 716 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000071 -> 0.000071\n",
            "(epoch: 717, iters: 4, time: 1.342) G_GAN_image: 2.655 G_GAN_person: 0.779 G_L1: 4.427 D_image_real: 0.190 D_image_fake: 0.009 D_person_real: 0.065 D_person_fake: 0.064 \n",
            "End of epoch 717 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000071 -> 0.000071\n",
            "End of epoch 718 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000071 -> 0.000070\n",
            "End of epoch 719 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000070 -> 0.000070\n",
            "End of epoch 720 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000070 -> 0.000070\n",
            "End of epoch 721 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000070 -> 0.000070\n",
            "End of epoch 722 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000070 -> 0.000069\n",
            "End of epoch 723 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000069 -> 0.000069\n",
            "End of epoch 724 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000069 -> 0.000069\n",
            "End of epoch 725 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000069 -> 0.000069\n",
            "End of epoch 726 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000069 -> 0.000068\n",
            "End of epoch 727 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000068 -> 0.000068\n",
            "End of epoch 728 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000068 -> 0.000068\n",
            "End of epoch 729 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000068 -> 0.000068\n",
            "End of epoch 730 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000068 -> 0.000067\n",
            "End of epoch 731 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000067 -> 0.000067\n",
            "End of epoch 732 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000067 -> 0.000067\n",
            "End of epoch 733 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000067 -> 0.000067\n",
            "(epoch: 734, iters: 2, time: 1.269) G_GAN_image: 5.490 G_GAN_person: 0.953 G_L1: 4.441 D_image_real: 0.271 D_image_fake: 0.223 D_person_real: 0.047 D_person_fake: 0.016 \n",
            "End of epoch 734 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000067 -> 0.000066\n",
            "End of epoch 735 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000066 -> 0.000066\n",
            "End of epoch 736 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000066 -> 0.000066\n",
            "End of epoch 737 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000066 -> 0.000066\n",
            "End of epoch 738 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000066 -> 0.000065\n",
            "End of epoch 739 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000065 -> 0.000065\n",
            "End of epoch 740 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000065 -> 0.000065\n",
            "End of epoch 741 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000065 -> 0.000065\n",
            "End of epoch 742 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000065 -> 0.000064\n",
            "End of epoch 743 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000064 -> 0.000064\n",
            "End of epoch 744 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000064 -> 0.000064\n",
            "End of epoch 745 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000064 -> 0.000064\n",
            "End of epoch 746 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000064 -> 0.000063\n",
            "End of epoch 747 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000063 -> 0.000063\n",
            "End of epoch 748 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000063 -> 0.000063\n",
            "End of epoch 749 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000063 -> 0.000063\n",
            "(epoch: 750, iters: 6, time: 1.838) G_GAN_image: 2.648 G_GAN_person: 0.788 G_L1: 4.220 D_image_real: 0.139 D_image_fake: 0.187 D_person_real: 0.081 D_person_fake: 0.022 \n",
            "End of epoch 750 / 1000 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000063 -> 0.000062\n",
            "End of epoch 751 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000062 -> 0.000062\n",
            "End of epoch 752 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000062 -> 0.000062\n",
            "End of epoch 753 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000062 -> 0.000062\n",
            "End of epoch 754 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000062 -> 0.000061\n",
            "End of epoch 755 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000061 -> 0.000061\n",
            "End of epoch 756 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000061 -> 0.000061\n",
            "End of epoch 757 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000061 -> 0.000061\n",
            "End of epoch 758 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000061 -> 0.000060\n",
            "End of epoch 759 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000060 -> 0.000060\n",
            "End of epoch 760 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000060 -> 0.000060\n",
            "End of epoch 761 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000060 -> 0.000060\n",
            "End of epoch 762 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000060 -> 0.000059\n",
            "End of epoch 763 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000059 -> 0.000059\n",
            "End of epoch 764 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000059 -> 0.000059\n",
            "End of epoch 765 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000059 -> 0.000059\n",
            "End of epoch 766 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000059 -> 0.000058\n",
            "(epoch: 767, iters: 4, time: 1.119) G_GAN_image: 4.171 G_GAN_person: 0.978 G_L1: 4.467 D_image_real: 0.065 D_image_fake: 0.027 D_person_real: 0.026 D_person_fake: 0.017 \n",
            "End of epoch 767 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000058 -> 0.000058\n",
            "End of epoch 768 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000058 -> 0.000058\n",
            "End of epoch 769 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000058 -> 0.000058\n",
            "End of epoch 770 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000058 -> 0.000057\n",
            "End of epoch 771 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000057 -> 0.000057\n",
            "End of epoch 772 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000057 -> 0.000057\n",
            "End of epoch 773 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000057 -> 0.000057\n",
            "End of epoch 774 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000057 -> 0.000056\n",
            "End of epoch 775 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000056 -> 0.000056\n",
            "End of epoch 776 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000056 -> 0.000056\n",
            "End of epoch 777 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000056 -> 0.000056\n",
            "End of epoch 778 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000056 -> 0.000055\n",
            "End of epoch 779 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000055 -> 0.000055\n",
            "End of epoch 780 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000055 -> 0.000055\n",
            "End of epoch 781 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000055 -> 0.000055\n",
            "End of epoch 782 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000055 -> 0.000054\n",
            "End of epoch 783 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000054 -> 0.000054\n",
            "(epoch: 784, iters: 2, time: 1.354) G_GAN_image: 1.752 G_GAN_person: 0.798 G_L1: 4.660 D_image_real: 0.411 D_image_fake: 0.212 D_person_real: 0.059 D_person_fake: 0.047 \n",
            "End of epoch 784 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000054 -> 0.000054\n",
            "End of epoch 785 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000054 -> 0.000054\n",
            "End of epoch 786 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000054 -> 0.000053\n",
            "End of epoch 787 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000053 -> 0.000053\n",
            "End of epoch 788 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000053 -> 0.000053\n",
            "End of epoch 789 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000053 -> 0.000053\n",
            "End of epoch 790 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000053 -> 0.000052\n",
            "End of epoch 791 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000052 -> 0.000052\n",
            "End of epoch 792 / 1000 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000052 -> 0.000052\n",
            "End of epoch 793 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000052 -> 0.000052\n",
            "End of epoch 794 / 1000 \t Time Taken: 2 sec\n",
            "update learning rate: 0.000052 -> 0.000051\n",
            "End of epoch 795 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000051 -> 0.000051\n",
            "End of epoch 796 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000051 -> 0.000051\n",
            "End of epoch 797 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000051 -> 0.000051\n",
            "End of epoch 798 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000051 -> 0.000050\n",
            "End of epoch 799 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000050 -> 0.000050\n",
            "(epoch: 800, iters: 6, time: 1.594) G_GAN_image: 3.654 G_GAN_person: 0.897 G_L1: 2.631 D_image_real: 0.064 D_image_fake: 0.021 D_person_real: 0.030 D_person_fake: 0.082 \n",
            "saving the latest model (epoch 800, total_steps 4800)\n",
            "saving the model at the end of epoch 800, iters 4800\n",
            "End of epoch 800 / 1000 \t Time Taken: 8 sec\n",
            "update learning rate: 0.000050 -> 0.000050\n",
            "End of epoch 801 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000050 -> 0.000050\n",
            "End of epoch 802 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000050 -> 0.000049\n",
            "End of epoch 803 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000049 -> 0.000049\n",
            "End of epoch 804 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000049 -> 0.000049\n",
            "End of epoch 805 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000049 -> 0.000049\n",
            "End of epoch 806 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000049 -> 0.000048\n",
            "End of epoch 807 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000048 -> 0.000048\n",
            "End of epoch 808 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000048 -> 0.000048\n",
            "End of epoch 809 / 1000 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000048 -> 0.000048\n",
            "End of epoch 810 / 1000 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000048 -> 0.000047\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# opt = TrainOptions().parse()\n",
        "data_loader = CreateDataLoader()\n",
        "dataset = data_loader.load_data()\n",
        "dataset_size = len(data_loader)\n",
        "print('#training images = %d' % dataset_size)\n",
        "#print(opt)\n",
        "model = create_model()\n",
        "visualizer = Visualizer()\n",
        "\n",
        "CRITIC_ITERS = 5\n",
        "total_steps = 0\n",
        "iter_d = 0\n",
        "only_d = False\n",
        "\n",
        "for epoch in range(1, niter + niter_decay + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    for i, data in enumerate(dataset):\n",
        "        iter_start_time = time.time()\n",
        "        total_steps += batchSize\n",
        "        epoch_iter = total_steps - dataset_size * (epoch - 1)\n",
        "        # y,x,w,h = data['bbox']\n",
        "        # if w[0]-x[0] < 39:\n",
        "        #     continue\n",
        "        model.set_input(data)\n",
        "#         if iter_d <= CRITIC_ITERS-1:\n",
        "#             only_d = False\n",
        "#         else:\n",
        "#             only_d = False\n",
        "        model.optimize_parameters(only_d)\n",
        "\n",
        "        if total_steps % display_freq == 0:\n",
        "            visualizer.display_current_results(model.get_current_visuals(), epoch)\n",
        "\n",
        "        if total_steps % print_freq == 0:\n",
        "            errors = model.get_current_errors()\n",
        "            t = (time.time() - iter_start_time) / batchSize\n",
        "            visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n",
        "            if display_id > 0:\n",
        "              pass\n",
        "                # visualizer.plot_current_errors(epoch, float(epoch_iter)/dataset_size, opt, errors)\n",
        "\n",
        "        if total_steps % save_latest_freq == 0:\n",
        "            print('saving the latest model (epoch %d, total_steps %d)' %\n",
        "                  (epoch, total_steps))\n",
        "            model.save('latest')\n",
        "        iter_d += 1\n",
        "        if iter_d == 6:\n",
        "            iter_d = 0\n",
        "\n",
        "    if epoch % save_epoch_freq == 0:\n",
        "        print('saving the model at the end of epoch %d, iters %d' %\n",
        "              (epoch, total_steps))\n",
        "        model.save('latest')\n",
        "        model.save(epoch)\n",
        "\n",
        "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
        "          (epoch, niter + niter_decay, time.time() - epoch_start_time))\n",
        "\n",
        "    if epoch > niter:\n",
        "        model.update_learning_rate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4zLjVJdX1Ax"
      },
      "source": [
        "#Test Script\n",
        "###changing some variables\n",
        "###Loads the latest saved model for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3499YI4JYxcK"
      },
      "outputs": [],
      "source": [
        "isTrain=False\n",
        "nThreads = 1   # test code only supports nThreads = 1\n",
        "batchSize = 1  # test code only supports batchSize = 1\n",
        "serial_batches = True  # no shuffle\n",
        "no_flip = True  # no flip\n",
        "phase='test'\n",
        "which_epoch='2800'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6DUuyNdX0Kf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "data_loader = CreateDataLoader()\n",
        "dataset = data_loader.load_data()\n",
        "model = create_model()\n",
        "visualizer = Visualizer()\n",
        "# create website\n",
        "web_dir = os.path.join(results_dir, name, '%s_%s' % (phase, which_epoch))\n",
        "webpage = html.HTML(web_dir, 'Experiment = %s, Phase = %s, Epoch = %s' % (name, phase, which_epoch))\n",
        "# test\n",
        "for i, data in enumerate(dataset):\n",
        "#    if i >= opt.how_many:\n",
        "#        break\n",
        "    model.set_input(data)\n",
        "    model.test()\n",
        "    visuals = model.get_current_visuals()\n",
        "    img_path = model.get_image_paths()\n",
        "    print('process image... %s' % img_path)\n",
        "    visualizer.save_images(webpage, visuals, img_path)\n",
        "\n",
        "webpage.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUE7yQWLG_v2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}