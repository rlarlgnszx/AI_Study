{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spatial Transformer Netowrk\n",
        "# STN\n",
        "## Vision 및 이미지 처리\n",
        "\n",
        "## 이미지/비디오 프레임이 회전하거나 일정하지 않은경우 STN으로 정적이미지를 가지고 분류기 실행 가능\n",
        "\n",
        "###2가지 주요 구성요소\n",
        "### Localization Net\n",
        "#### 관심 객체가 어디에 있는지 알아내는것\n",
        "#### 목표가 어디에 있는지 알아냄\n",
        "#### 그다음 개체에서 그리드 생성\n",
        "#### 그다음 샘플러를 통해 안정적 이미지를 가짐\n",
        "\n"
      ],
      "metadata": {
        "id": "NL7XNkMRY5BF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#즉 훈련데이터 세트의 성능향상을 목표로하는 Transformer Network임"
      ],
      "metadata": {
        "id": "PY8wExSuecd4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "flUHxkfWLx-u"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.io.matlab import loadmat\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://www.cs.toronto.edu/~tijmen/affNIST/32x/transformed/training_and_validation_batches.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlyk_FShL7tB",
        "outputId": "13616b9c-a656-42db-e2f1-a7d0c95e2019"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-30 08:20:54--  https://www.cs.toronto.edu/~tijmen/affNIST/32x/transformed/training_and_validation_batches.zip\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 730609891 (697M) [application/zip]\n",
            "Saving to: ‘training_and_validation_batches.zip’\n",
            "\n",
            "training_and_valida 100%[===================>] 696.76M  13.5MB/s    in 52s     \n",
            "\n",
            "2023-06-30 08:21:47 (13.3 MB/s) - ‘training_and_validation_batches.zip’ saved [730609891/730609891]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip training_and_validation_batches.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfCFEY3AL96l",
        "outputId": "edcf7bb0-e254-46e4-ec8e-fe4f60ab7e47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  training_and_validation_batches.zip\n",
            "   creating: training_and_validation_batches/\n",
            "  inflating: training_and_validation_batches/1.mat  \n",
            "  inflating: training_and_validation_batches/2.mat  \n",
            "  inflating: training_and_validation_batches/3.mat  \n",
            "  inflating: training_and_validation_batches/4.mat  \n",
            "  inflating: training_and_validation_batches/5.mat  \n",
            "  inflating: training_and_validation_batches/6.mat  \n",
            "  inflating: training_and_validation_batches/7.mat  \n",
            "  inflating: training_and_validation_batches/8.mat  \n",
            "  inflating: training_and_validation_batches/9.mat  \n",
            "  inflating: training_and_validation_batches/10.mat  \n",
            "  inflating: training_and_validation_batches/11.mat  \n",
            "  inflating: training_and_validation_batches/12.mat  \n",
            "  inflating: training_and_validation_batches/13.mat  \n",
            "  inflating: training_and_validation_batches/14.mat  \n",
            "  inflating: training_and_validation_batches/15.mat  \n",
            "  inflating: training_and_validation_batches/16.mat  \n",
            "  inflating: training_and_validation_batches/17.mat  \n",
            "  inflating: training_and_validation_batches/18.mat  \n",
            "  inflating: training_and_validation_batches/19.mat  \n",
            "  inflating: training_and_validation_batches/20.mat  \n",
            "  inflating: training_and_validation_batches/21.mat  \n",
            "  inflating: training_and_validation_batches/22.mat  \n",
            "  inflating: training_and_validation_batches/23.mat  \n",
            "  inflating: training_and_validation_batches/24.mat  \n",
            "  inflating: training_and_validation_batches/25.mat  \n",
            "  inflating: training_and_validation_batches/26.mat  \n",
            "  inflating: training_and_validation_batches/27.mat  \n",
            "  inflating: training_and_validation_batches/28.mat  \n",
            "  inflating: training_and_validation_batches/29.mat  \n",
            "  inflating: training_and_validation_batches/30.mat  \n",
            "  inflating: training_and_validation_batches/31.mat  \n",
            "  inflating: training_and_validation_batches/32.mat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_data_path = 'training_and_validation_batches/1.mat'\n",
        "temp = loadmat(image_data_path)\n",
        "## affNISTData?\n",
        "### Matlab의 Data Array\n",
        "x = temp['affNISTdata']['image'][0][0].reshape(40, 40, 60000)\n",
        "x = np.moveaxis(x, -1, 0)\n",
        "x = (np.expand_dims(x, axis=-1)) / 255\n",
        "\n",
        "y = temp['affNISTdata']['label_int'][0][0]\n",
        "y = np.moveaxis(y, -1, 0).astype(np.int32)"
      ],
      "metadata": {
        "id": "R0Kog_JYMC89"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulmhnmt5adzc",
        "outputId": "1516d6a8-a77b-41da-e603-cfdec257e4f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Tue Jul 30 17:40:01 2013',\n",
              " '__version__': '1.0',\n",
              " '__globals__': [],\n",
              " 'affNISTdata': array([[(array([[  0.89156558,   1.22424824,   1.07444537, ...,   0.84506806,\n",
              "                   0.84181203,   1.01685128],\n",
              "                [  0.20984936,   0.09023881,   0.35236942, ...,  -0.10444246,\n",
              "                  -0.38555402,  -0.36578185],\n",
              "                [ -1.26476551, -19.79984702,  -4.67021712, ...,  -1.24599817,\n",
              "                   9.86595301,   7.51251838],\n",
              "                [ -0.17483301,  -0.02143027,  -0.31830479, ...,  -0.06015251,\n",
              "                   0.20168488,   0.25395146],\n",
              "                [  0.99727444,   0.9962823 ,   0.87274986, ...,   1.05586096,\n",
              "                   0.85924446,   0.93983876],\n",
              "                [ -5.93082082,   4.60322027,   2.7601324 , ...,   5.63800333,\n",
              "                  -0.21749138, -18.41544233]]), array([[ 1.07717478e+00,  8.15534765e-01,  8.31283035e-01, ...,\n",
              "                  1.19172756e+00,  1.07260389e+00,  8.96307709e-01],\n",
              "                [-2.26662225e-01, -7.38675032e-02, -3.35627344e-01, ...,\n",
              "                  1.17881954e-01,  4.81291139e-01,  3.48839723e-01],\n",
              "                [ 1.80804730e-02,  1.64874920e+01,  4.80864817e+00, ...,\n",
              "                  8.20271509e-01, -1.04775829e+01, -3.09490337e-01],\n",
              "                [ 1.88840403e-01,  1.75423455e-02,  3.03181224e-01, ...,\n",
              "                  6.78928483e-02, -2.51765353e-01, -2.42189044e-01],\n",
              "                [ 9.62996669e-01,  1.00214267e+00,  1.02339542e+00, ...,\n",
              "                  9.53810145e-01,  1.05084281e+00,  9.69753204e-01],\n",
              "                [ 5.95019953e+00, -4.26574769e+00, -1.40878472e+00, ...,\n",
              "                 -5.29299040e+00,  2.71245439e+00,  1.96778838e+01]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
              "                [0, 0, 0, ..., 0, 0, 0],\n",
              "                [0, 0, 0, ..., 0, 0, 0],\n",
              "                ...,\n",
              "                [0, 0, 0, ..., 0, 0, 0],\n",
              "                [0, 0, 0, ..., 0, 0, 0],\n",
              "                [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), array([[    1,     2,     3, ..., 59998, 59999, 60000]]), array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "                [0., 1., 0., ..., 0., 0., 1.],\n",
              "                [0., 0., 0., ..., 0., 0., 0.],\n",
              "                ...,\n",
              "                [0., 0., 1., ..., 0., 1., 0.],\n",
              "                [0., 0., 0., ..., 0., 0., 0.],\n",
              "                [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([[0, 1, 7, ..., 3, 7, 1]]), array([[ 1.10947272e+01,  1.00285094e+00,  1.65019398e+01, ...,\n",
              "                  4.07148511e+00, -1.34732061e+01, -1.40223821e+01],\n",
              "                [-1.37585321e-02, -7.29550325e-02, -9.60118765e-02, ...,\n",
              "                  1.71303682e-01,  1.88828685e-01,  1.27099471e-01],\n",
              "                [ 1.10065978e+00,  8.16702686e-01,  8.92376796e-01, ...,\n",
              "                  1.18035019e+00,  1.15522106e+00,  9.54122952e-01],\n",
              "                [ 9.81337497e-01,  1.00229619e+00,  1.06735985e+00, ...,\n",
              "                  9.56223421e-01,  1.08058151e+00,  9.99538298e-01],\n",
              "                [-8.00000000e+00,  7.00000000e+00, -8.00000000e+00, ...,\n",
              "                 -1.00000000e+00, -9.00000000e+00, -3.00000000e+00],\n",
              "                [ 2.00000000e+00, -1.00000000e+01, -3.00000000e+00, ...,\n",
              "                 -1.10000000e+01, -6.00000000e+00,  1.00000000e+01]]), array([[    1,     2,     3, ..., 59998, 59999, 60000]]))                                 ]],\n",
              "       dtype=[('matrix_new_to_old', 'O'), ('matrix_old_to_new', 'O'), ('image', 'O'), ('affNIST_id', 'O'), ('label_one_of_n', 'O'), ('label_int', 'O'), ('human_readable_transform', 'O'), ('original_id', 'O')])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp[\"affNISTdata\"]['image'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPa7jmY3ccKv",
        "outputId": "34c38115-692a-468b-b282-c9f686a4d3ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow_datasets as tfds\n",
        "# (mnist_train_ds, mnist_test_ds), ds_info = tfds.load(\n",
        "#     'mnist',\n",
        "#     split=['train', 'test'],\n",
        "#     shuffle_files=True,\n",
        "#     as_supervised=True,\n",
        "#     with_info=True,\n",
        "# )\n",
        "\n",
        "# (28,28)"
      ],
      "metadata": {
        "id": "uVmUPfj9WnI7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "-mXqwbfZMGGY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "mnist_train_ds = mnist_train_ds.shuffle(5000).batch(128)"
      ],
      "metadata": {
        "id": "hK6KG6a_MI5G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LocalizationNetwork(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LocalizationNetwork, self).__init__()\n",
        "        ## 더 복잡한 LocalizationNet을 얻길 원하면 pool,conv 복\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
        "        self.pool3 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc1 = tf.keras.layers.Dense(20, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(6, activation=None, bias_initializer=tf.keras.initializers.constant([1.0, 0.0, 0.0, 0.0, 1.0, 0.0]), kernel_initializer='zeros')\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        print(\"Building Localization Network with input shape:\", input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [None, 6]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        theta = self.fc2(x)\n",
        "        theta = tf.keras.layers.Reshape((2, 3))(theta)\n",
        "        return theta"
      ],
      "metadata": {
        "id": "KvBiOiBJML8g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BilinearInterpolation\n",
        "## Grid Generator를 찾는것\n"
      ],
      "metadata": {
        "id": "YcBH0atCbwzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BilinearInterpolation(tf.keras.layers.Layer):\n",
        "    def __init__(self, height=40, width=40):#들어오는 iamge size\n",
        "        super(BilinearInterpolation, self).__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [None, self.height, self.width, 1]\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'height': self.height,\n",
        "            'width': self.width,\n",
        "        }\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        print(\"Building Bilinear Interpolation Layer with input shape:\", input_shape)\n",
        "\n",
        "    ## generator에서 index를 여러번 알아내는 용도로 사용\n",
        "    def advance_indexing(self, inputs, x, y):\n",
        "        shape = tf.shape(inputs)\n",
        "        batch_size, _, _ = shape[0], shape[1], shape[2]\n",
        "\n",
        "        batch_idx = tf.range(0, batch_size)\n",
        "        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
        "        b = tf.tile(batch_idx, (1, self.height, self.width))\n",
        "        indices = tf.stack([b, y, x], 3)\n",
        "        return tf.gather_nd(inputs, indices)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        images, theta = inputs\n",
        "        homogenous_coordinates = self.grid_generator(batch=tf.shape(images)[0])\n",
        "        return self.interpolate(images, homogenous_coordinates, theta)\n",
        "\n",
        "    # 관심 객체 주위에 grid 생성\n",
        "    def grid_generator(self, batch):\n",
        "        x = tf.linspace(-1, 1, self.width)\n",
        "        y = tf.linspace(-1, 1, self.height)\n",
        "\n",
        "        xx, yy = tf.meshgrid(x, y)\n",
        "        xx = tf.reshape(xx, (-1,))\n",
        "        yy = tf.reshape(yy, (-1,))\n",
        "        homogenous_coordinates = tf.stack([xx, yy, tf.ones_like(xx)])\n",
        "        homogenous_coordinates = tf.expand_dims(homogenous_coordinates, axis=0)\n",
        "        homogenous_coordinates = tf.tile(homogenous_coordinates, [batch, 1, 1])\n",
        "        homogenous_coordinates = tf.cast(homogenous_coordinates, dtype=tf.float32)\n",
        "        return homogenous_coordinates\n",
        "    ## pixel을 변환하는 것\n",
        "    def interpolate(self, images, homogenous_coordinates, theta):\n",
        "\n",
        "        with tf.name_scope(\"Transformation\"):\n",
        "            transformed = tf.matmul(theta, homogenous_coordinates)\n",
        "            transformed = tf.transpose(transformed, perm=[0, 2, 1])\n",
        "            transformed = tf.reshape(transformed, [-1, self.height, self.width, 2])\n",
        "\n",
        "            x_transformed = transformed[:, :, :, 0]\n",
        "            y_transformed = transformed[:, :, :, 1]\n",
        "\n",
        "            x = ((x_transformed + 1.) * tf.cast(self.width, dtype=tf.float32)) * 0.5\n",
        "            y = ((y_transformed + 1.) * tf.cast(self.height, dtype=tf.float32)) * 0.5\n",
        "\n",
        "        with tf.name_scope(\"VariableCasting\"):\n",
        "            x0 = tf.cast(tf.math.floor(x), dtype=tf.int32)\n",
        "            x1 = x0 + 1\n",
        "            y0 = tf.cast(tf.math.floor(y), dtype=tf.int32)\n",
        "            y1 = y0 + 1\n",
        "\n",
        "            x0 = tf.clip_by_value(x0, 0, self.width-1)\n",
        "            x1 = tf.clip_by_value(x1, 0, self.width-1)\n",
        "            y0 = tf.clip_by_value(y0, 0, self.height-1)\n",
        "            y1 = tf.clip_by_value(y1, 0, self.height-1)\n",
        "            x = tf.clip_by_value(x, 0, tf.cast(self.width, dtype=tf.float32)-1.0)\n",
        "            y = tf.clip_by_value(y, 0, tf.cast(self.height, dtype=tf.float32)-1)\n",
        "\n",
        "        with tf.name_scope(\"AdvanceIndexing\"):\n",
        "            Ia = self.advance_indexing(images, x0, y0)\n",
        "            Ib = self.advance_indexing(images, x0, y1)\n",
        "            Ic = self.advance_indexing(images, x1, y0)\n",
        "            Id = self.advance_indexing(images, x1, y1)\n",
        "\n",
        "        with tf.name_scope(\"Interpolation\"):\n",
        "            x0 = tf.cast(x0, dtype=tf.float32)\n",
        "            x1 = tf.cast(x1, dtype=tf.float32)\n",
        "            y0 = tf.cast(y0, dtype=tf.float32)\n",
        "            y1 = tf.cast(y1, dtype=tf.float32)\n",
        "\n",
        "            wa = (x1-x) * (y1-y)\n",
        "            wb = (x1-x) * (y-y0)\n",
        "            wc = (x-x0) * (y1-y)\n",
        "            wd = (x-x0) * (y-y0)\n",
        "\n",
        "            wa = tf.expand_dims(wa, axis=3)\n",
        "            wb = tf.expand_dims(wb, axis=3)\n",
        "            wc = tf.expand_dims(wc, axis=3)\n",
        "            wd = tf.expand_dims(wd, axis=3)\n",
        "\n",
        "        return tf.math.add_n([wa*Ia + wb*Ib + wc*Ic + wd*Id])"
      ],
      "metadata": {
        "id": "PNaR-B5lMO9S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bi = BilinearInterpolation()"
      ],
      "metadata": {
        "id": "HlHpRlC6MSr9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 먼저 Localization Network으로 전달후\n",
        "### BilinearInterpolation 수행"
      ],
      "metadata": {
        "id": "LtWJ61PAc27Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (40, 40, 1)\n",
        "image = tf.keras.layers.Input(shape=input_shape)\n",
        "theta = LocalizationNetwork()(image)\n",
        "x = BilinearInterpolation(height=input_shape[0], width=input_shape[1])([image, theta])\n",
        "x = tf.keras.layers.Conv2D(64, [9, 9], activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Conv2D(64, [7, 7], activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "## Dense에 들어가기 전에 Flatten 해주는 것이 정말 중요\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=image, outputs=x)"
      ],
      "metadata": {
        "id": "j3-Yb_X7Mauf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab7458d-3141-4a6b-f189-c17f44120134"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Localization Network with input shape: (None, 40, 40, 1)\n",
            "Building Bilinear Interpolation Layer with input shape: [TensorShape([None, 40, 40, 1]), TensorShape([None, 2, 3])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from_logits 여러개의 출력을 가지게 된다.\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "rJnX_tv3MeXn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(mnist_train_ds, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91S51sHwMkL1",
        "outputId": "dffb8496-9245-49b8-c970-e37566e4976b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422/422 [==============================] - 43s 57ms/step - loss: 0.5708 - accuracy: 0.8093\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 19s 45ms/step - loss: 0.1249 - accuracy: 0.9621\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 18s 44ms/step - loss: 0.0861 - accuracy: 0.9736\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 15s 35ms/step - loss: 0.0682 - accuracy: 0.9789\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 19s 45ms/step - loss: 0.0586 - accuracy: 0.9820\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 16s 37ms/step - loss: 0.0513 - accuracy: 0.9841\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 15s 36ms/step - loss: 0.0485 - accuracy: 0.9840\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 14s 34ms/step - loss: 0.0458 - accuracy: 0.9856\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 15s 36ms/step - loss: 0.0402 - accuracy: 0.9872\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 14s 34ms/step - loss: 0.0380 - accuracy: 0.9878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# outputs=[model.layers[1].output, model.layers[2].output]\n",
        "### layer1.output=> Localization에 의한것\n",
        "### layer2.output=> Bilinear interpolation에 의한것"
      ],
      "metadata": {
        "id": "9WI8jMbQd1ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Model(inputs=model.inputs, outputs=[model.layers[1].output, model.layers[2].output])"
      ],
      "metadata": {
        "id": "tj0asyq9VQWT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta, prediction = model.predict(X_test)"
      ],
      "metadata": {
        "id": "6_lNmzhpMlq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba4b164-6084-420c-fd4f-6f2a9c544fd5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 2s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2vnYyMdd8C",
        "outputId": "c51a100f-acfd-4c58-dc7f-f1f0d893fde0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 즉 이것은 훈련데이터 세트를 향상시키기위한\n",
        "### Spatial Transformer Network를 사용하는 방법"
      ],
      "metadata": {
        "id": "Cf8gYspweQXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.imshow(X_test[12, :, :, 0], cmap='gray')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(prediction[12, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "V7g1_k25VAJX",
        "outputId": "95266ac2-1f70-47a1-8339-69106ec5cf16"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3635651c00>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_jt_vzcV-t8"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}